{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to DEHB's documentation!","text":""},{"location":"#introduction","title":"Introduction","text":"<p><code>dehb</code> is a python package implementing the DEHB algorithm. It offers an intuitive interface to optimize user-defined problems using DEHB.</p> <p>This documentation explains how to use <code>dehb</code> and demonstrates its features. In the following section you will be guided how to install the <code>dehb</code> package and how to use it in your own projects. Examples with more hands-on material can be found in the examples folder.</p>"},{"location":"#installation","title":"Installation","text":"<p>To start using the <code>dehb</code> package, you can install it via pip. You can either install the package right from git or install it as an editable package to modify the code and rerun your experiments:</p> <pre><code># Install from pypi\npip install dehb\n</code></pre> <p>From Source</p> <p>To install directly from from source</p> <pre><code>git clone https://github.com/automl/DEHB.git\npip install -e DEHB  # -e stands for editable, lets you modify the code and rerun things\n</code></pre>"},{"location":"#contributing","title":"Contributing","text":"<p>Please have a look at our contributing guidelines.</p>"},{"location":"#to-cite-the-paper-or-code","title":"To cite the paper or code","text":"<p>If you use DEHB in one of your research projects, please cite our paper(s): <pre><code>@inproceedings{awad-ijcai21,\nauthor    = {N. Awad and N. Mallik and F. Hutter},\ntitle     = {{DEHB}: Evolutionary Hyberband for Scalable, Robust and Efficient Hyperparameter Optimization},\npages     = {2147--2153},\nbooktitle = {Proceedings of the Thirtieth International Joint Conference on\n               Artificial Intelligence, {IJCAI-21}},\npublisher = {ijcai.org},\neditor    = {Z. Zhou},\nyear      = {2021}\n}\n</code></pre></p>"},{"location":"getting_started/parallel/","title":"Parallel","text":""},{"location":"getting_started/parallel/#running-dehb-in-a-parallel-setting","title":"Running DEHB in a parallel setting","text":"<p>DEHB has been designed to interface a Dask client. DEHB can either create a Dask client during instantiation and close/kill the client during garbage collection.  Or a client can be passed as an argument during instantiation.</p> <ul> <li>Setting <code>n_workers</code> during instantiation \\     If set to <code>1</code> (default) then the entire process is a sequential run without invoking Dask. \\     If set to <code>&gt;1</code> then a Dask Client is initialized with as many workers as <code>n_workers</code>. \\     This parameter is ignored if <code>client</code> is not None.</li> <li>Setting <code>client</code> during instantiation \\     When <code>None</code> (default), a Dask client is created using <code>n_workers</code> specified. \\     Else, any custom-configured Dask Client can be created and passed as the <code>client</code> argument to DEHB.</li> </ul>"},{"location":"getting_started/parallel/#using-gpus-in-a-parallel-run","title":"Using GPUs in a parallel run","text":"<p>Certain target function evaluations (especially for Deep Learning) require computations to be  carried out on GPUs. The GPU devices are often ordered by device ID and if not configured, all  spawned worker processes access these devices in the same order and can either run out of memory or not exhibit parallelism.</p> <p>For <code>n_workers&gt;1</code> and when running on a single node (or local), the <code>single_node_with_gpus</code> can be  passed to the <code>run()</code> call to DEHB. Setting it to <code>False</code> (default) has no effect on the default setup  of the machine. Setting it to <code>True</code> will reorder the GPU device IDs dynamically by setting the environment  variable <code>CUDA_VISIBLE_DEVICES</code> for each worker process executing a target function evaluation. The re-ordering  is done in a manner that the first priority device is the one with the least number of active jobs assigned  to it by that DEHB run.</p> <p>To run the PyTorch MNIST example on a single node using 2 workers: <pre><code>python examples/03_pytorch_mnist_hpo.py \\\n--min_budget 1 \\\n--max_budget 3 \\\n--runtime 60 \\\n--n_workers 2 \\\n--single_node_with_gpus \\\n--verbose\n</code></pre></p>"},{"location":"getting_started/parallel/#multi-node-runs","title":"Multi-node runs","text":"<p>Multi-node parallelism is often contingent on the cluster setup to be deployed on. Dask provides useful  frameworks to interface various cluster designs. As long as the <code>client</code> passed to DEHB during  instantiation is of type <code>dask.distributed.Client</code>, DEHB can interact with this client and  distribute its optimization process in a parallel manner. </p> <p>For instance, <code>Dask-CLI</code> can be used to create a <code>dask-scheduler</code> which can dump its connection  details to a file on a cluster node accessible to all processes. Multiple <code>dask-worker</code> can then be created to interface the <code>dask-scheduler</code> by connecting to the details read from the file dumped. Each dask-worker can be triggered on any remote machine. Each worker can be configured as required,  including mapping to specific GPU devices. </p> <p>Some helper scripts can be found here, that can be used as a reference to run DEHB in a multi-node  manner on clusters managed by SLURM. (not expected to work off-the-shelf)</p> <p>To run the PyTorch MNIST example on a multi-node setup using 4 workers: <pre><code>bash utils/run_dask_setup.sh \\\n-n 4 \\\n-f dask_dump/scheduler.json \\   # This is how the workers will be discovered by DEHB\n-e env_name\n\n# Make sure to sleep to allow the workers to setup properly\nsleep 5\npython examples/03_pytorch_mnist_hpo.py \\\n--min_budget 1 \\\n--max_budget 3 \\\n--runtime 60 \\\n--scheduler_file dask_dump/scheduler.json \\\n--verbose\n</code></pre></p>"},{"location":"getting_started/single_worker/","title":"Single Worker","text":""},{"location":"getting_started/single_worker/#basic-single-worker-setup","title":"Basic single worker setup","text":"<p>A basic setup for optimizing can be done as follows. Please note, that this is example should solely show a simple setup of <code>dehb</code>. More in-depth examples can be found in the examples folder. First we need to setup a <code>ConfigurationSpace</code>, from which Configurations will be sampled:</p> Configuration Space<pre><code>from ConfigSpace import ConfigurationSpace, Configuration\ncs = ConfigurationSpace({\"x0\": (3.0, 10.0), \"x1\": [\"red\", \"green\"]})\nprint(cs)\n</code></pre> <pre><code>Configuration space object:\nHyperparameters:\nx0, Type: UniformFloat, Range: [3.0, 10.0], Default: 6.5\nx1, Type: Categorical, Choices: {red, green}, Default: red\n</code></pre> <p>Next, we need an <code>object_function</code>, which we are aiming to optimize: Configuration Space<pre><code>import numpy as np\ndef objective_function(x: Configuration, budget: float, **kwargs):\n# Replace this with your actual objective value (y) and cost.\ncost = (10 if x[\"x1\"] == \"red\" else 100) + budget\ny = x[\"x0\"] + np.random.uniform()\nreturn {\"fitness\": y, \"cost\": x[\"x0\"]}\nsample_config = cs.sample_configuration()\nprint(sample_config)\nresult = objective_function(sample_config, budget=10)\nprint(result)\n</code></pre> <pre><code>Configuration(values={\n'x0': 3.369835437896851,\n'x1': 'green',\n})\n{'fitness': 3.9874157820161615, 'cost': 3.369835437896851}\n</code></pre> </p> <p>Finally, we can setup our optimizer and run DEHB:</p> Configuration Space<pre><code>from dehb import DEHB\ndim = len(cs.get_hyperparameters())\noptimizer = DEHB(\nf=objective_function,\ncs=cs,\ndimensions=dim,\nmin_budget=3,\nmax_budget=27,\neta=3,\nn_workers=1,\noutput_path=\"./logs\",\n)\n# Run optimization for 1 bracket. Output files will be saved to ./logs\ntraj, runtime, history = optimizer.run(brackets=1, verbose=True)\nconfig, fitness, runtime, budget, _ = history[0]\nprint(\"config\", config)\nprint(\"fitness\", fitness)\nprint(\"runtime\", runtime)\nprint(\"budget\", budget)\n</code></pre> <pre><code>config [0.6972659796126406, 0.5]\nfitness 8.390062866775258\nruntime 7.880861857288484\nbudget 3.0\n</code></pre>"},{"location":"references/bracket_manager/","title":"Bracket manager","text":""},{"location":"references/bracket_manager/#dehb.utils.bracket_manager.SHBracketManager","title":"<code>SHBracketManager(n_configs, budgets, bracket_id=None)</code>","text":"<p>         Bases: <code>object</code></p> <p>Synchronous Successive Halving utilities</p> Source code in <code>src/dehb/utils/bracket_manager.py</code> <pre><code>def __init__(self, n_configs, budgets, bracket_id=None):\nassert len(n_configs) == len(budgets)\nself.n_configs = n_configs\nself.budgets = budgets\nself.bracket_id = bracket_id\nself.sh_bracket = {}\nself._sh_bracket = {}\nself._config_map = {}\nfor i, budget in enumerate(budgets):\n# sh_bracket keeps track of jobs/configs that are still to be scheduled/allocatted\n# _sh_bracket keeps track of jobs/configs that have been run and results retrieved for\n# (sh_bracket[i] + _sh_bracket[i]) == n_configs[i] is when no jobs have been scheduled\n#   or all jobs for that budget/rung are over\n# (sh_bracket[i] + _sh_bracket[i]) &lt; n_configs[i] indicates a job has been scheduled\n#   and is queued/running and the bracket needs to be paused till results are retrieved\nself.sh_bracket[budget] = n_configs[i]  # each scheduled job does -= 1\nself._sh_bracket[budget] = 0  # each retrieved job does +=1\nself.n_rungs = len(budgets)\nself.current_rung = 0\n</code></pre>"},{"location":"references/bracket_manager/#dehb.utils.bracket_manager.SHBracketManager.get_budget","title":"<code>get_budget(rung=None)</code>","text":"<p>Returns the exact budget that rung is pointing to.</p> <p>Returns current rung's budget if no rung is passed.</p> Source code in <code>src/dehb/utils/bracket_manager.py</code> <pre><code>def get_budget(self, rung=None):\n\"\"\" Returns the exact budget that rung is pointing to.\n    Returns current rung's budget if no rung is passed.\n    \"\"\"\nif rung is not None:\nreturn self.budgets[rung]\nreturn self.budgets[self.current_rung]\n</code></pre>"},{"location":"references/bracket_manager/#dehb.utils.bracket_manager.SHBracketManager.get_lower_budget_promotions","title":"<code>get_lower_budget_promotions(budget)</code>","text":"<p>Returns the immediate lower budget and the number of configs to be promoted from there</p> Source code in <code>src/dehb/utils/bracket_manager.py</code> <pre><code>def get_lower_budget_promotions(self, budget):\n\"\"\" Returns the immediate lower budget and the number of configs to be promoted from there\n    \"\"\"\nassert budget in self.budgets\nrung = np.where(budget == self.budgets)[0][0]\nprev_rung = np.clip(rung - 1, a_min=0, a_max=self.n_rungs-1)\nlower_budget = self.budgets[prev_rung]\nnum_promote_configs = self.n_configs[rung]\nreturn lower_budget, num_promote_configs\n</code></pre>"},{"location":"references/bracket_manager/#dehb.utils.bracket_manager.SHBracketManager.get_next_job_budget","title":"<code>get_next_job_budget()</code>","text":"<p>Returns the budget that will be selected if current_rung is incremented by 1</p> Source code in <code>src/dehb/utils/bracket_manager.py</code> <pre><code>def get_next_job_budget(self):\n\"\"\" Returns the budget that will be selected if current_rung is incremented by 1\n    \"\"\"\nif self.sh_bracket[self.get_budget()] &gt; 0:\n# the current rung still has unallocated jobs (&gt;0)\nreturn self.get_budget()\nelse:\n# the current rung has no more jobs to allocate, increment it\nrung = (self.current_rung + 1) % self.n_rungs\nif self.sh_bracket[self.get_budget(rung)] &gt; 0:\n# the incremented rung has unallocated jobs (&gt;0)\nreturn self.get_budget(rung)\nelse:\n# all jobs for this bracket has been allocated/bracket is complete\n# no more budgets to evaluate and can return None\npass\nreturn None\n</code></pre>"},{"location":"references/bracket_manager/#dehb.utils.bracket_manager.SHBracketManager.register_job","title":"<code>register_job(budget)</code>","text":"<p>Registers the allocation of a configuration for the budget and updates current rung</p> <p>This function must be called when scheduling a job in order to allow the bracket manager to continue job and budget allocation without waiting for jobs to finish and return results necessarily. This feature can be leveraged to run brackets asynchronously.</p> Source code in <code>src/dehb/utils/bracket_manager.py</code> <pre><code>def register_job(self, budget):\n\"\"\" Registers the allocation of a configuration for the budget and updates current rung\n    This function must be called when scheduling a job in order to allow the bracket manager\n    to continue job and budget allocation without waiting for jobs to finish and return\n    results necessarily. This feature can be leveraged to run brackets asynchronously.\n    \"\"\"\nassert budget in self.budgets\nassert self.sh_bracket[budget] &gt; 0\nself.sh_bracket[budget] -= 1\nif not self._is_rung_pending(self.current_rung):\n# increment current rung if no jobs left in the rung\nself.current_rung = (self.current_rung + 1) % self.n_rungs\n</code></pre>"},{"location":"references/bracket_manager/#dehb.utils.bracket_manager.SHBracketManager.complete_job","title":"<code>complete_job(budget)</code>","text":"<p>Notifies the bracket that a job for a budget has been completed</p> <p>This function must be called when a config for a budget has finished evaluation to inform the Bracket Manager that no job needs to be waited for and the next rung can begin for the synchronous Successive Halving case.</p> Source code in <code>src/dehb/utils/bracket_manager.py</code> <pre><code>def complete_job(self, budget):\n\"\"\" Notifies the bracket that a job for a budget has been completed\n    This function must be called when a config for a budget has finished evaluation to inform\n    the Bracket Manager that no job needs to be waited for and the next rung can begin for the\n    synchronous Successive Halving case.\n    \"\"\"\nassert budget in self.budgets\n_max_configs = self.n_configs[list(self.budgets).index(budget)]\nassert self._sh_bracket[budget] &lt; _max_configs\nself._sh_bracket[budget] += 1\n</code></pre>"},{"location":"references/bracket_manager/#dehb.utils.bracket_manager.SHBracketManager.previous_rung_waits","title":"<code>previous_rung_waits()</code>","text":"<p>Returns True if none of the rungs &lt; current rung is waiting for results</p> Source code in <code>src/dehb/utils/bracket_manager.py</code> <pre><code>def previous_rung_waits(self):\n\"\"\" Returns True if none of the rungs &lt; current rung is waiting for results\n    \"\"\"\nfor rung in range(self.current_rung):\nif self._is_rung_waiting(rung) and not self._is_rung_pending(rung):\nreturn True\nreturn False\n</code></pre>"},{"location":"references/bracket_manager/#dehb.utils.bracket_manager.SHBracketManager.is_bracket_done","title":"<code>is_bracket_done()</code>","text":"<p>Returns True if all configs in all rungs in the bracket have been allocated</p> Source code in <code>src/dehb/utils/bracket_manager.py</code> <pre><code>def is_bracket_done(self):\n\"\"\" Returns True if all configs in all rungs in the bracket have been allocated\n    \"\"\"\nreturn ~self.is_pending() and ~self.is_waiting()\n</code></pre>"},{"location":"references/bracket_manager/#dehb.utils.bracket_manager.SHBracketManager.is_pending","title":"<code>is_pending()</code>","text":"<p>Returns True if any of the rungs/budgets have still a configuration to submit</p> Source code in <code>src/dehb/utils/bracket_manager.py</code> <pre><code>def is_pending(self):\n\"\"\" Returns True if any of the rungs/budgets have still a configuration to submit\n    \"\"\"\nreturn np.any([self._is_rung_pending(i) &gt; 0 for i, _ in enumerate(self.budgets)])\n</code></pre>"},{"location":"references/bracket_manager/#dehb.utils.bracket_manager.SHBracketManager.is_waiting","title":"<code>is_waiting()</code>","text":"<p>Returns True if any of the rungs/budgets have a configuration pending/running</p> Source code in <code>src/dehb/utils/bracket_manager.py</code> <pre><code>def is_waiting(self):\n\"\"\" Returns True if any of the rungs/budgets have a configuration pending/running\n    \"\"\"\nreturn np.any([self._is_rung_waiting(i) &gt; 0 for i, _ in enumerate(self.budgets)])\n</code></pre>"},{"location":"references/de/","title":"DE","text":""},{"location":"references/de/#dehb.optimizers.de.DEBase","title":"<code>DEBase(cs=None, f=None, dimensions=None, pop_size=None, max_age=None, mutation_factor=None, crossover_prob=None, strategy=None, budget=None, boundary_fix_type='random', **kwargs)</code>","text":"<p>Base class for Differential Evolution</p> Source code in <code>src/dehb/optimizers/de.py</code> <pre><code>def __init__(self, cs=None, f=None, dimensions=None, pop_size=None, max_age=None,\nmutation_factor=None, crossover_prob=None, strategy=None, budget=None,\nboundary_fix_type='random', **kwargs):\n# Benchmark related variables\nself.cs = cs\nself.f = f\nif dimensions is None and self.cs is not None:\nself.dimensions = len(self.cs.get_hyperparameters())\nelse:\nself.dimensions = dimensions\n# DE related variables\nself.pop_size = pop_size\nself.max_age = max_age\nself.mutation_factor = mutation_factor\nself.crossover_prob = crossover_prob\nself.strategy = strategy\nself.budget = budget\nself.fix_type = boundary_fix_type\n# Miscellaneous\nself.configspace = True if isinstance(self.cs, ConfigSpace.ConfigurationSpace) else False\nself.hps = dict()\nif self.configspace:\nfor i, hp in enumerate(cs.get_hyperparameters()):\n# maps hyperparameter name to positional index in vector form\nself.hps[hp.name] = i\nself.output_path = kwargs['output_path'] if 'output_path' in kwargs else './'\nos.makedirs(self.output_path, exist_ok=True)\n# Global trackers\nself.inc_score = np.inf\nself.inc_config = None\nself.population = None\nself.fitness = None\nself.age = None\nself.history = []\n</code></pre>"},{"location":"references/de/#dehb.optimizers.de.DEBase.sample_population","title":"<code>sample_population(size=3, alt_pop=None)</code>","text":"<p>Samples 'size' individuals</p> <p>If alt_pop is None or a list/array of None, sample from own population Else sample from the specified alternate population (alt_pop)</p> Source code in <code>src/dehb/optimizers/de.py</code> <pre><code>def sample_population(self, size: int = 3, alt_pop: List = None) -&gt; List:\n'''Samples 'size' individuals\n    If alt_pop is None or a list/array of None, sample from own population\n    Else sample from the specified alternate population (alt_pop)\n    '''\nif isinstance(alt_pop, list) or isinstance(alt_pop, np.ndarray):\nidx = [indv is None for indv in alt_pop]\nif any(idx):\nselection = np.random.choice(np.arange(len(self.population)), size, replace=False)\nreturn self.population[selection]\nelse:\nif len(alt_pop) &lt; 3:\nalt_pop = np.vstack((alt_pop, self.population))\nselection = np.random.choice(np.arange(len(alt_pop)), size, replace=False)\nalt_pop = np.stack(alt_pop)\nreturn alt_pop[selection]\nelse:\nselection = np.random.choice(np.arange(len(self.population)), size, replace=False)\nreturn self.population[selection]\n</code></pre>"},{"location":"references/de/#dehb.optimizers.de.DEBase.boundary_check","title":"<code>boundary_check(vector)</code>","text":"<p>Checks whether each of the dimensions of the input vector are within [0, 1]. If not, values of those dimensions are replaced with the type of fix selected.</p> <p>if fix_type == 'random', the values are replaced with a random sampling from (0,1) if fix_type == 'clip', the values are clipped to the closest limit from {0, 1}</p>"},{"location":"references/de/#dehb.optimizers.de.DEBase.boundary_check--parameters","title":"Parameters","text":"<p>vector : array</p>"},{"location":"references/de/#dehb.optimizers.de.DEBase.boundary_check--returns","title":"Returns","text":"<p>array</p> Source code in <code>src/dehb/optimizers/de.py</code> <pre><code>def boundary_check(self, vector: np.array) -&gt; np.array:\n'''\n    Checks whether each of the dimensions of the input vector are within [0, 1].\n    If not, values of those dimensions are replaced with the type of fix selected.\n    if fix_type == 'random', the values are replaced with a random sampling from (0,1)\n    if fix_type == 'clip', the values are clipped to the closest limit from {0, 1}\n    Parameters\n    ----------\n    vector : array\n    Returns\n    -------\n    array\n    '''\nviolations = np.where((vector &gt; 1) | (vector &lt; 0))[0]\nif len(violations) == 0:\nreturn vector\nif self.fix_type == 'random':\nvector[violations] = np.random.uniform(low=0.0, high=1.0, size=len(violations))\nelse:\nvector[violations] = np.clip(vector[violations], a_min=0, a_max=1)\nreturn vector\n</code></pre>"},{"location":"references/de/#dehb.optimizers.de.DEBase.vector_to_configspace","title":"<code>vector_to_configspace(vector)</code>","text":"<p>Converts numpy array to ConfigSpace object</p> <p>Works when self.cs is a ConfigSpace object and the input vector is in the domain [0, 1].</p> Source code in <code>src/dehb/optimizers/de.py</code> <pre><code>def vector_to_configspace(self, vector: np.array) -&gt; ConfigSpace.Configuration:\n'''Converts numpy array to ConfigSpace object\n    Works when self.cs is a ConfigSpace object and the input vector is in the domain [0, 1].\n    '''\n# creates a ConfigSpace object dict with all hyperparameters present, the inactive too\nnew_config = ConfigSpace.util.impute_inactive_values(\nself.cs.sample_configuration()\n).get_dictionary()\n# iterates over all hyperparameters and normalizes each based on its type\nfor i, hyper in enumerate(self.cs.get_hyperparameters()):\nif type(hyper) == ConfigSpace.OrdinalHyperparameter:\nranges = np.arange(start=0, stop=1, step=1/len(hyper.sequence))\nparam_value = hyper.sequence[np.where((vector[i] &lt; ranges) == False)[0][-1]]\nelif type(hyper) == ConfigSpace.CategoricalHyperparameter:\nranges = np.arange(start=0, stop=1, step=1/len(hyper.choices))\nparam_value = hyper.choices[np.where((vector[i] &lt; ranges) == False)[0][-1]]\nelif type(hyper) == ConfigSpace.Constant:\nparam_value = hyper.default_value\nelse:  # handles UniformFloatHyperparameter &amp; UniformIntegerHyperparameter\n# rescaling continuous values\nif hyper.log:\nlog_range = np.log(hyper.upper) - np.log(hyper.lower)\nparam_value = np.exp(np.log(hyper.lower) + vector[i] * log_range)\nelse:\nparam_value = hyper.lower + (hyper.upper - hyper.lower) * vector[i]\nif type(hyper) == ConfigSpace.UniformIntegerHyperparameter:\nparam_value = int(np.round(param_value))  # converting to discrete (int)\nelse:\nparam_value = float(param_value)\nnew_config[hyper.name] = param_value\n# the mapping from unit hypercube to the actual config space may lead to illegal\n# configurations based on conditions defined, which need to be deactivated/removed\nnew_config = ConfigSpace.util.deactivate_inactive_hyperparameters(\nconfiguration = new_config, configuration_space=self.cs\n)\nreturn new_config\n</code></pre>"},{"location":"references/de/#dehb.optimizers.de.DEBase.configspace_to_vector","title":"<code>configspace_to_vector(config)</code>","text":"<p>Converts ConfigSpace object to numpy array scaled to [0,1]</p> <p>Works when self.cs is a ConfigSpace object and the input config is a ConfigSpace object. Handles conditional spaces implicitly by replacing illegal parameters with default values to maintain the dimensionality of the vector.</p> Source code in <code>src/dehb/optimizers/de.py</code> <pre><code>def configspace_to_vector(self, config: ConfigSpace.Configuration) -&gt; np.array:\n'''Converts ConfigSpace object to numpy array scaled to [0,1]\n    Works when self.cs is a ConfigSpace object and the input config is a ConfigSpace object.\n    Handles conditional spaces implicitly by replacing illegal parameters with default values\n    to maintain the dimensionality of the vector.\n    '''\n# the imputation replaces illegal parameter values with their default\nconfig = ConfigSpace.util.impute_inactive_values(config)\ndimensions = len(self.cs.get_hyperparameters())\nvector = [np.nan for i in range(dimensions)]\nfor name in config:\ni = self.hps[name]\nhyper = self.cs.get_hyperparameter(name)\nif type(hyper) == ConfigSpace.OrdinalHyperparameter:\nnlevels = len(hyper.sequence)\nvector[i] = hyper.sequence.index(config[name]) / nlevels\nelif type(hyper) == ConfigSpace.CategoricalHyperparameter:\nnlevels = len(hyper.choices)\nvector[i] = hyper.choices.index(config[name]) / nlevels\nelif type(hyper) == ConfigSpace.Constant:\nvector[i] = 0 # set constant to 0, so that it wont be affected by mutation\nelse:\nbounds = (hyper.lower, hyper.upper)\nparam_value = config[name]\nif hyper.log:\nvector[i] = np.log(param_value / bounds[0]) / np.log(bounds[1] / bounds[0])\nelse:\nvector[i] = (config[name] - bounds[0]) / (bounds[1] - bounds[0])\nreturn np.array(vector)\n</code></pre>"},{"location":"references/de/#dehb.optimizers.de.DE","title":"<code>DE(cs=None, f=None, dimensions=None, pop_size=20, max_age=np.inf, mutation_factor=None, crossover_prob=None, strategy='rand1_bin', budget=None, encoding=False, dim_map=None, **kwargs)</code>","text":"<p>         Bases: <code>DEBase</code></p> Source code in <code>src/dehb/optimizers/de.py</code> <pre><code>def __init__(self, cs=None, f=None, dimensions=None, pop_size=20, max_age=np.inf,\nmutation_factor=None, crossover_prob=None, strategy='rand1_bin',\nbudget=None, encoding=False, dim_map=None, **kwargs):\nsuper().__init__(cs=cs, f=f, dimensions=dimensions, pop_size=pop_size, max_age=max_age,\nmutation_factor=mutation_factor, crossover_prob=crossover_prob,\nstrategy=strategy, budget=budget, **kwargs)\nif self.strategy is not None:\nself.mutation_strategy = self.strategy.split('_')[0]\nself.crossover_strategy = self.strategy.split('_')[1]\nelse:\nself.mutation_strategy = self.crossover_strategy = None\nself.encoding = encoding\nself.dim_map = dim_map\nself._set_min_pop_size()\n</code></pre>"},{"location":"references/de/#dehb.optimizers.de.DE.__getstate__","title":"<code>__getstate__()</code>","text":"<p>Allows the object to picklable while having Dask client as a class attribute.</p> Source code in <code>src/dehb/optimizers/de.py</code> <pre><code>def __getstate__(self):\n\"\"\" Allows the object to picklable while having Dask client as a class attribute.\n    \"\"\"\nd = dict(self.__dict__)\nd[\"client\"] = None  # hack to allow Dask client to be a class attribute\nd[\"logger\"] = None  # hack to allow logger object to be a class attribute\nreturn d\n</code></pre>"},{"location":"references/de/#dehb.optimizers.de.DE.__del__","title":"<code>__del__()</code>","text":"<p>Ensures a clean kill of the Dask client and frees up a port.</p> Source code in <code>src/dehb/optimizers/de.py</code> <pre><code>def __del__(self):\n\"\"\" Ensures a clean kill of the Dask client and frees up a port.\n    \"\"\"\nif hasattr(self, \"client\") and isinstance(self.client, Client):\nself.client.close()\n</code></pre>"},{"location":"references/de/#dehb.optimizers.de.DE.init_eval_pop","title":"<code>init_eval_pop(budget=None, eval=True, **kwargs)</code>","text":"<p>Creates new population of 'pop_size' and evaluates individuals.</p> Source code in <code>src/dehb/optimizers/de.py</code> <pre><code>def init_eval_pop(self, budget=None, eval=True, **kwargs):\n'''Creates new population of 'pop_size' and evaluates individuals.\n    '''\nself.population = self.init_population(self.pop_size)\nself.fitness = np.array([np.inf for i in range(self.pop_size)])\nself.age = np.array([self.max_age] * self.pop_size)\ntraj = []\nruntime = []\nhistory = []\nif not eval:\nreturn traj, runtime, history\nfor i in range(self.pop_size):\nconfig = self.population[i]\nres = self.f_objective(config, budget, **kwargs)\nself.fitness[i], cost = res[\"fitness\"], res[\"cost\"]\ninfo = res[\"info\"] if \"info\" in res else dict()\nif self.fitness[i] &lt; self.inc_score:\nself.inc_score = self.fitness[i]\nself.inc_config = config\ntraj.append(self.inc_score)\nruntime.append(cost)\nhistory.append((config.tolist(), float(self.fitness[i]), float(budget or 0), info))\nreturn traj, runtime, history\n</code></pre>"},{"location":"references/de/#dehb.optimizers.de.DE.eval_pop","title":"<code>eval_pop(population=None, budget=None, **kwargs)</code>","text":"<p>Evaluates a population</p> <p>If population=None, the current population's fitness will be evaluated If population!=None, this population will be evaluated</p> Source code in <code>src/dehb/optimizers/de.py</code> <pre><code>def eval_pop(self, population=None, budget=None, **kwargs):\n'''Evaluates a population\n    If population=None, the current population's fitness will be evaluated\n    If population!=None, this population will be evaluated\n    '''\npop = self.population if population is None else population\npop_size = self.pop_size if population is None else len(pop)\ntraj = []\nruntime = []\nhistory = []\nfitnesses = []\ncosts = []\nages = []\nfor i in range(pop_size):\nres = self.f_objective(pop[i], budget, **kwargs)\nfitness, cost = res[\"fitness\"], res[\"cost\"]\ninfo = res[\"info\"] if \"info\" in res else dict()\nif population is None:\nself.fitness[i] = fitness\nif fitness &lt;= self.inc_score:\nself.inc_score = fitness\nself.inc_config = pop[i]\ntraj.append(self.inc_score)\nruntime.append(cost)\nhistory.append((pop[i].tolist(), float(fitness), float(budget or 0), info))\nfitnesses.append(fitness)\ncosts.append(cost)\nages.append(self.max_age)\nif population is None:\nself.fitness = np.array(fitnesses)\nreturn traj, runtime, history\nelse:\nreturn traj, runtime, history, np.array(fitnesses), np.array(ages)\n</code></pre>"},{"location":"references/de/#dehb.optimizers.de.DE.mutation_rand1","title":"<code>mutation_rand1(r1, r2, r3)</code>","text":"<p>Performs the 'rand1' type of DE mutation</p> Source code in <code>src/dehb/optimizers/de.py</code> <pre><code>def mutation_rand1(self, r1, r2, r3):\n'''Performs the 'rand1' type of DE mutation\n    '''\ndiff = r2 - r3\nmutant = r1 + self.mutation_factor * diff\nreturn mutant\n</code></pre>"},{"location":"references/de/#dehb.optimizers.de.DE.mutation_rand2","title":"<code>mutation_rand2(r1, r2, r3, r4, r5)</code>","text":"<p>Performs the 'rand2' type of DE mutation</p> Source code in <code>src/dehb/optimizers/de.py</code> <pre><code>def mutation_rand2(self, r1, r2, r3, r4, r5):\n'''Performs the 'rand2' type of DE mutation\n    '''\ndiff1 = r2 - r3\ndiff2 = r4 - r5\nmutant = r1 + self.mutation_factor * diff1 + self.mutation_factor * diff2\nreturn mutant\n</code></pre>"},{"location":"references/de/#dehb.optimizers.de.DE.mutation","title":"<code>mutation(current=None, best=None, alt_pop=None)</code>","text":"<p>Performs DE mutation</p> Source code in <code>src/dehb/optimizers/de.py</code> <pre><code>def mutation(self, current=None, best=None, alt_pop=None):\n'''Performs DE mutation\n    '''\nif self.mutation_strategy == 'rand1':\nr1, r2, r3 = self.sample_population(size=3, alt_pop=alt_pop)\nmutant = self.mutation_rand1(r1, r2, r3)\nelif self.mutation_strategy == 'rand2':\nr1, r2, r3, r4, r5 = self.sample_population(size=5, alt_pop=alt_pop)\nmutant = self.mutation_rand2(r1, r2, r3, r4, r5)\nelif self.mutation_strategy == 'rand2dir':\nr1, r2, r3 = self.sample_population(size=3, alt_pop=alt_pop)\nmutant = self.mutation_rand2dir(r1, r2, r3)\nelif self.mutation_strategy == 'best1':\nr1, r2 = self.sample_population(size=2, alt_pop=alt_pop)\nif best is None:\nbest = self.population[np.argmin(self.fitness)]\nmutant = self.mutation_rand1(best, r1, r2)\nelif self.mutation_strategy == 'best2':\nr1, r2, r3, r4 = self.sample_population(size=4, alt_pop=alt_pop)\nif best is None:\nbest = self.population[np.argmin(self.fitness)]\nmutant = self.mutation_rand2(best, r1, r2, r3, r4)\nelif self.mutation_strategy == 'currenttobest1':\nr1, r2 = self.sample_population(size=2, alt_pop=alt_pop)\nif best is None:\nbest = self.population[np.argmin(self.fitness)]\nmutant = self.mutation_currenttobest1(current, best, r1, r2)\nelif self.mutation_strategy == 'randtobest1':\nr1, r2, r3 = self.sample_population(size=3, alt_pop=alt_pop)\nif best is None:\nbest = self.population[np.argmin(self.fitness)]\nmutant = self.mutation_currenttobest1(r1, best, r2, r3)\nreturn mutant\n</code></pre>"},{"location":"references/de/#dehb.optimizers.de.DE.crossover_bin","title":"<code>crossover_bin(target, mutant)</code>","text":"<p>Performs the binomial crossover of DE</p> Source code in <code>src/dehb/optimizers/de.py</code> <pre><code>def crossover_bin(self, target, mutant):\n'''Performs the binomial crossover of DE\n    '''\ncross_points = np.random.rand(self.dimensions) &lt; self.crossover_prob\nif not np.any(cross_points):\ncross_points[np.random.randint(0, self.dimensions)] = True\noffspring = np.where(cross_points, mutant, target)\nreturn offspring\n</code></pre>"},{"location":"references/de/#dehb.optimizers.de.DE.crossover_exp","title":"<code>crossover_exp(target, mutant)</code>","text":"<p>Performs the exponential crossover of DE</p> Source code in <code>src/dehb/optimizers/de.py</code> <pre><code>def crossover_exp(self, target, mutant):\n'''Performs the exponential crossover of DE\n    '''\nn = np.random.randint(0, self.dimensions)\nL = 0\nwhile ((np.random.rand() &lt; self.crossover_prob) and L &lt; self.dimensions):\nidx = (n+L) % self.dimensions\ntarget[idx] = mutant[idx]\nL = L + 1\nreturn target\n</code></pre>"},{"location":"references/de/#dehb.optimizers.de.DE.crossover","title":"<code>crossover(target, mutant)</code>","text":"<p>Performs DE crossover</p> Source code in <code>src/dehb/optimizers/de.py</code> <pre><code>def crossover(self, target, mutant):\n'''Performs DE crossover\n    '''\nif self.crossover_strategy == 'bin':\noffspring = self.crossover_bin(target, mutant)\nelif self.crossover_strategy == 'exp':\noffspring = self.crossover_exp(target, mutant)\nreturn offspring\n</code></pre>"},{"location":"references/de/#dehb.optimizers.de.DE.selection","title":"<code>selection(trials, budget=None, **kwargs)</code>","text":"<p>Carries out a parent-offspring competition given a set of trial population</p> Source code in <code>src/dehb/optimizers/de.py</code> <pre><code>def selection(self, trials, budget=None, **kwargs):\n'''Carries out a parent-offspring competition given a set of trial population\n    '''\ntraj = []\nruntime = []\nhistory = []\nfor i in range(len(trials)):\n# evaluation of the newly created individuals\nres = self.f_objective(trials[i], budget, **kwargs)\nfitness, cost = res[\"fitness\"], res[\"cost\"]\ninfo = res[\"info\"] if \"info\" in res else dict()\n# selection -- competition between parent[i] -- child[i]\n## equality is important for landscape exploration\nif fitness &lt;= self.fitness[i]:\nself.population[i] = trials[i]\nself.fitness[i] = fitness\n# resetting age since new individual in the population\nself.age[i] = self.max_age\nelse:\n# decreasing age by 1 of parent who is better than offspring/trial\nself.age[i] -= 1\n# updation of global incumbent for trajectory\nif self.fitness[i] &lt; self.inc_score:\nself.inc_score = self.fitness[i]\nself.inc_config = self.population[i]\ntraj.append(self.inc_score)\nruntime.append(cost)\nhistory.append((trials[i].tolist(), float(fitness), float(budget or 0), info))\nreturn traj, runtime, history\n</code></pre>"},{"location":"references/de/#dehb.optimizers.de.DE.evolve_generation","title":"<code>evolve_generation(budget=None, best=None, alt_pop=None, **kwargs)</code>","text":"<p>Performs a complete DE evolution: mutation -&gt; crossover -&gt; selection</p> Source code in <code>src/dehb/optimizers/de.py</code> <pre><code>def evolve_generation(self, budget=None, best=None, alt_pop=None, **kwargs):\n'''Performs a complete DE evolution: mutation -&gt; crossover -&gt; selection\n    '''\ntrials = []\nfor j in range(self.pop_size):\ntarget = self.population[j]\ndonor = self.mutation(current=target, best=best, alt_pop=alt_pop)\ntrial = self.crossover(target, donor)\ntrial = self.boundary_check(trial)\ntrials.append(trial)\ntrials = np.array(trials)\ntraj, runtime, history = self.selection(trials, budget, **kwargs)\nreturn traj, runtime, history\n</code></pre>"},{"location":"references/de/#dehb.optimizers.de.DE.sample_mutants","title":"<code>sample_mutants(size, population=None)</code>","text":"<p>Generates 'size' mutants from the population using rand1</p> Source code in <code>src/dehb/optimizers/de.py</code> <pre><code>def sample_mutants(self, size, population=None):\n'''Generates 'size' mutants from the population using rand1\n    '''\nif population is None:\npopulation = self.population\nelif len(population) &lt; 3:\npopulation = np.vstack((self.population, population))\nold_strategy = self.mutation_strategy\nself.mutation_strategy = 'rand1'\nmutants = np.random.uniform(low=0.0, high=1.0, size=(size, self.dimensions))\nfor i in range(size):\nmutant = self.mutation(current=None, best=None, alt_pop=population)\nmutants[i] = self.boundary_check(mutant)\nself.mutation_strategy = old_strategy\nreturn mutants\n</code></pre>"},{"location":"references/de/#dehb.optimizers.de.AsyncDE","title":"<code>AsyncDE(cs=None, f=None, dimensions=None, pop_size=None, max_age=np.inf, mutation_factor=None, crossover_prob=None, strategy='rand1_bin', budget=None, async_strategy='immediate', **kwargs)</code>","text":"<p>         Bases: <code>DE</code></p> <p>Extends DE to be Asynchronous with variations</p>"},{"location":"references/de/#dehb.optimizers.de.AsyncDE--parameters","title":"Parameters","text":"str <p>'deferred' - target will be chosen sequentially from the population     the winner of the selection step will be included in the population only after     the entire population has had a selection step in that generation 'immediate' - target will be chosen sequentially from the population     the winner of the selection step is included in the population right away 'random' - target will be chosen randomly from the population for mutation-crossover     the winner of the selection step is included in the population right away 'worst' - the worst individual will be chosen as the target     the winner of the selection step is included in the population right away {immediate, worst, random} implement Asynchronous-DE</p> Source code in <code>src/dehb/optimizers/de.py</code> <pre><code>def __init__(self, cs=None, f=None, dimensions=None, pop_size=None, max_age=np.inf,\nmutation_factor=None, crossover_prob=None, strategy='rand1_bin',\nbudget=None, async_strategy='immediate', **kwargs):\n'''Extends DE to be Asynchronous with variations\n    Parameters\n    ----------\n    async_strategy : str\n        'deferred' - target will be chosen sequentially from the population\n            the winner of the selection step will be included in the population only after\n            the entire population has had a selection step in that generation\n        'immediate' - target will be chosen sequentially from the population\n            the winner of the selection step is included in the population right away\n        'random' - target will be chosen randomly from the population for mutation-crossover\n            the winner of the selection step is included in the population right away\n        'worst' - the worst individual will be chosen as the target\n            the winner of the selection step is included in the population right away\n        {immediate, worst, random} implement Asynchronous-DE\n    '''\nsuper().__init__(cs=cs, f=f, dimensions=dimensions, pop_size=pop_size, max_age=max_age,\nmutation_factor=mutation_factor, crossover_prob=crossover_prob,\nstrategy=strategy, budget=budget, **kwargs)\nif self.strategy is not None:\nself.mutation_strategy = self.strategy.split('_')[0]\nself.crossover_strategy = self.strategy.split('_')[1]\nelse:\nself.mutation_strategy = self.crossover_strategy = None\nself.async_strategy = async_strategy\nassert self.async_strategy in ['immediate', 'random', 'worst', 'deferred'], \\\n            \"{} is not a valid choice for type of DE\".format(self.async_strategy)\n</code></pre>"},{"location":"references/de/#dehb.optimizers.de.AsyncDE.mutation","title":"<code>mutation(current=None, best=None, alt_pop=None)</code>","text":"<p>Performs DE mutation</p> Source code in <code>src/dehb/optimizers/de.py</code> <pre><code>def mutation(self, current=None, best=None, alt_pop=None):\n'''Performs DE mutation\n    '''\nif self.mutation_strategy == 'rand1':\nr1, r2, r3 = self._sample_population(size=3, alt_pop=alt_pop, target=current)\nmutant = self.mutation_rand1(r1, r2, r3)\nelif self.mutation_strategy == 'rand2':\nr1, r2, r3, r4, r5 = self._sample_population(size=5, alt_pop=alt_pop, target=current)\nmutant = self.mutation_rand2(r1, r2, r3, r4, r5)\nelif self.mutation_strategy == 'rand2dir':\nr1, r2, r3 = self._sample_population(size=3, alt_pop=alt_pop, target=current)\nmutant = self.mutation_rand2dir(r1, r2, r3)\nelif self.mutation_strategy == 'best1':\nr1, r2 = self._sample_population(size=2, alt_pop=alt_pop, target=current)\nif best is None:\nbest = self.population[np.argmin(self.fitness)]\nmutant = self.mutation_rand1(best, r1, r2)\nelif self.mutation_strategy == 'best2':\nr1, r2, r3, r4 = self._sample_population(size=4, alt_pop=alt_pop, target=current)\nif best is None:\nbest = self.population[np.argmin(self.fitness)]\nmutant = self.mutation_rand2(best, r1, r2, r3, r4)\nelif self.mutation_strategy == 'currenttobest1':\nr1, r2 = self._sample_population(size=2, alt_pop=alt_pop, target=current)\nif best is None:\nbest = self.population[np.argmin(self.fitness)]\nmutant = self.mutation_currenttobest1(current, best, r1, r2)\nelif self.mutation_strategy == 'randtobest1':\nr1, r2, r3 = self._sample_population(size=3, alt_pop=alt_pop, target=current)\nif best is None:\nbest = self.population[np.argmin(self.fitness)]\nmutant = self.mutation_currenttobest1(r1, best, r2, r3)\nreturn mutant\n</code></pre>"},{"location":"references/de/#dehb.optimizers.de.AsyncDE.sample_mutants","title":"<code>sample_mutants(size, population=None)</code>","text":"<p>Samples 'size' mutants from the population</p> Source code in <code>src/dehb/optimizers/de.py</code> <pre><code>def sample_mutants(self, size, population=None):\n'''Samples 'size' mutants from the population\n    '''\nif population is None:\npopulation = self.population\nmutants = np.random.uniform(low=0.0, high=1.0, size=(size, self.dimensions))\nfor i in range(size):\nj = np.random.choice(np.arange(len(population)))\nmutant = self.mutation(current=population[j], best=self.inc_config, alt_pop=population)\nmutants[i] = self.boundary_check(mutant)\nreturn mutants\n</code></pre>"},{"location":"references/de/#dehb.optimizers.de.AsyncDE.evolve_generation","title":"<code>evolve_generation(budget=None, best=None, alt_pop=None, **kwargs)</code>","text":"<p>Performs a complete DE evolution, mutation -&gt; crossover -&gt; selection</p> Source code in <code>src/dehb/optimizers/de.py</code> <pre><code>def evolve_generation(self, budget=None, best=None, alt_pop=None, **kwargs):\n'''Performs a complete DE evolution, mutation -&gt; crossover -&gt; selection\n    '''\ntraj = []\nruntime = []\nhistory = []\nif self.async_strategy == 'deferred':\ntrials = []\nfor j in range(self.pop_size):\ntarget = self.population[j]\ndonor = self.mutation(current=target, best=best, alt_pop=alt_pop)\ntrial = self.crossover(target, donor)\ntrial = self.boundary_check(trial)\ntrials.append(trial)\n# selection takes place on a separate trial population only after\n# one iteration through the population has taken place\ntrials = np.array(trials)\ntraj, runtime, history = self.selection(trials, budget, **kwargs)\nreturn traj, runtime, history\nelif self.async_strategy == 'immediate':\nfor i in range(self.pop_size):\ntarget = self.population[i]\ndonor = self.mutation(current=target, best=best, alt_pop=alt_pop)\ntrial = self.crossover(target, donor)\ntrial = self.boundary_check(trial)\n# evaluating a single trial population for the i-th individual\nde_traj, de_runtime, de_history, fitnesses, costs = \\\n                self.eval_pop(trial.reshape(1, self.dimensions), budget=budget, **kwargs)\n# one-vs-one selection\n## can replace the i-the population despite not completing one iteration\nif fitnesses[0] &lt;= self.fitness[i]:\nself.population[i] = trial\nself.fitness[i] = fitnesses[0]\ntraj.extend(de_traj)\nruntime.extend(de_runtime)\nhistory.extend(de_history)\nreturn traj, runtime, history\nelse:  # async_strategy == 'random' or async_strategy == 'worst':\nfor count in range(self.pop_size):\n# choosing target individual\nif self.async_strategy == 'random':\ni = np.random.choice(np.arange(self.pop_size))\nelse:  # async_strategy == 'worst'\ni = np.argsort(-self.fitness)[0]\ntarget = self.population[i]\nmutant = self.mutation(current=target, best=best, alt_pop=alt_pop)\ntrial = self.crossover(target, mutant)\ntrial = self.boundary_check(trial)\n# evaluating a single trial population for the i-th individual\nde_traj, de_runtime, de_history, fitnesses, costs = \\\n                self.eval_pop(trial.reshape(1, self.dimensions), budget=budget, **kwargs)\n# one-vs-one selection\n## can replace the i-the population despite not completing one iteration\nif fitnesses[0] &lt;= self.fitness[i]:\nself.population[i] = trial\nself.fitness[i] = fitnesses[0]\ntraj.extend(de_traj)\nruntime.extend(de_runtime)\nhistory.extend(de_history)\nreturn traj, runtime, history\n</code></pre>"},{"location":"references/dehb/","title":"DEHB","text":""},{"location":"references/dehb/#dehb.optimizers.dehb.DEHBBase","title":"<code>DEHBBase(cs=None, f=None, dimensions=None, mutation_factor=None, crossover_prob=None, strategy=None, min_budget=None, max_budget=None, eta=None, min_clip=None, max_clip=None, boundary_fix_type='random', max_age=np.inf, **kwargs)</code>","text":"Source code in <code>src/dehb/optimizers/dehb.py</code> <pre><code>def __init__(self, cs=None, f=None, dimensions=None, mutation_factor=None,\ncrossover_prob=None, strategy=None, min_budget=None,\nmax_budget=None, eta=None, min_clip=None, max_clip=None,\nboundary_fix_type='random', max_age=np.inf, **kwargs):\n# Miscellaneous\nself._setup_logger(kwargs)\n# Benchmark related variables\nself.cs = cs\nself.configspace = True if isinstance(self.cs, ConfigSpace.ConfigurationSpace) else False\nif self.configspace:\nself.dimensions = len(self.cs.get_hyperparameters())\nelif dimensions is None or not isinstance(dimensions, (int, np.integer)):\nassert \"Need to specify `dimensions` as an int when `cs` is not available/specified!\"\nelse:\nself.dimensions = dimensions\nself.f = f\n# DE related variables\nself.mutation_factor = mutation_factor\nself.crossover_prob = crossover_prob\nself.strategy = strategy\nself.fix_type = boundary_fix_type\nself.max_age = max_age\nself.de_params = {\n\"mutation_factor\": self.mutation_factor,\n\"crossover_prob\": self.crossover_prob,\n\"strategy\": self.strategy,\n\"configspace\": self.configspace,\n\"boundary_fix_type\": self.fix_type,\n\"max_age\": self.max_age,\n\"cs\": self.cs,\n\"dimensions\": self.dimensions,\n\"f\": f\n}\n# Hyperband related variables\nself.min_budget = min_budget\nself.max_budget = max_budget\nif self.max_budget &lt;= self.min_budget:\nself.logger.error(\"Only (Max Budget &gt; Min Budget) is supported for DEHB.\")\nif self.max_budget == self.min_budget:\nself.logger.error(\n\"If you have a fixed fidelity, \" \\\n                \"you can instead run DE. For more information checkout: \" \\\n                \"https://automl.github.io/DEHB/references/de\")\nraise AssertionError()\nself.eta = eta\nself.min_clip = min_clip\nself.max_clip = max_clip\n# Precomputing budget spacing and number of configurations for HB iterations\nself.max_SH_iter = None\nself.budgets = None\nif self.min_budget is not None and \\\n       self.max_budget is not None and \\\n       self.eta is not None:\nself.max_SH_iter = -int(np.log(self.min_budget / self.max_budget) / np.log(self.eta)) + 1\nself.budgets = self.max_budget * np.power(self.eta,\n-np.linspace(start=self.max_SH_iter - 1,\nstop=0, num=self.max_SH_iter))\n# Updating DE parameter list\nself.de_params.update({\"output_path\": self.output_path})\n# Global trackers\nself.population = None\nself.fitness = None\nself.inc_score = np.inf\nself.inc_config = None\nself.history = []\n</code></pre>"},{"location":"references/dehb/#dehb.optimizers.dehb.DEHBBase.get_next_iteration","title":"<code>get_next_iteration(iteration)</code>","text":"<p>Computes the Successive Halving spacing</p> <p>Given the iteration index, computes the budget spacing to be used and the number of configurations to be used for the SH iterations.</p>"},{"location":"references/dehb/#dehb.optimizers.dehb.DEHBBase.get_next_iteration--parameters","title":"Parameters","text":"int <p>Iteration index</p> int, {1, 2, 3, ..., None} <p>If not None, clips the minimum number of configurations to 'clip'</p>"},{"location":"references/dehb/#dehb.optimizers.dehb.DEHBBase.get_next_iteration--returns","title":"Returns","text":"<p>ns : array budgets : array</p> Source code in <code>src/dehb/optimizers/dehb.py</code> <pre><code>def get_next_iteration(self, iteration):\n'''Computes the Successive Halving spacing\n    Given the iteration index, computes the budget spacing to be used and\n    the number of configurations to be used for the SH iterations.\n    Parameters\n    ----------\n    iteration : int\n        Iteration index\n    clip : int, {1, 2, 3, ..., None}\n        If not None, clips the minimum number of configurations to 'clip'\n    Returns\n    -------\n    ns : array\n    budgets : array\n    '''\n# number of 'SH runs'\ns = self.max_SH_iter - 1 - (iteration % self.max_SH_iter)\n# budget spacing for this iteration\nbudgets = self.budgets[(-s-1):]\n# number of configurations in that bracket\nn0 = int(np.floor((self.max_SH_iter)/(s+1)) * self.eta**s)\nns = [max(int(n0*(self.eta**(-i))), 1) for i in range(s+1)]\nif self.min_clip is not None and self.max_clip is not None:\nns = np.clip(ns, a_min=self.min_clip, a_max=self.max_clip)\nelif self.min_clip is not None:\nns = np.clip(ns, a_min=self.min_clip, a_max=np.max(ns))\nreturn ns, budgets\n</code></pre>"},{"location":"references/dehb/#dehb.optimizers.dehb.DEHBBase.get_incumbents","title":"<code>get_incumbents()</code>","text":"<p>Returns a tuple of the (incumbent configuration, incumbent score/fitness).</p> Source code in <code>src/dehb/optimizers/dehb.py</code> <pre><code>def get_incumbents(self):\n\"\"\" Returns a tuple of the (incumbent configuration, incumbent score/fitness). \"\"\"\nif self.configspace:\nreturn self.vector_to_configspace(self.inc_config), self.inc_score\nreturn self.inc_config, self.inc_score\n</code></pre>"},{"location":"references/dehb/#dehb.optimizers.dehb.DEHB","title":"<code>DEHB(cs=None, f=None, dimensions=None, mutation_factor=0.5, crossover_prob=0.5, strategy='rand1_bin', min_budget=None, max_budget=None, eta=3, min_clip=None, max_clip=None, configspace=True, boundary_fix_type='random', max_age=np.inf, n_workers=None, client=None, async_strategy='immediate', **kwargs)</code>","text":"<p>         Bases: <code>DEHBBase</code></p> Source code in <code>src/dehb/optimizers/dehb.py</code> <pre><code>def __init__(self, cs=None, f=None, dimensions=None, mutation_factor=0.5,\ncrossover_prob=0.5, strategy='rand1_bin', min_budget=None,\nmax_budget=None, eta=3, min_clip=None, max_clip=None, configspace=True,\nboundary_fix_type='random', max_age=np.inf, n_workers=None, client=None,\nasync_strategy=\"immediate\", **kwargs):\nsuper().__init__(cs=cs, f=f, dimensions=dimensions, mutation_factor=mutation_factor,\ncrossover_prob=crossover_prob, strategy=strategy, min_budget=min_budget,\nmax_budget=max_budget, eta=eta, min_clip=min_clip, max_clip=max_clip,\nconfigspace=configspace, boundary_fix_type=boundary_fix_type,\nmax_age=max_age, **kwargs)\nself.de_params.update({\"async_strategy\": async_strategy})\nself.iteration_counter = -1\nself.de = {}\nself._max_pop_size = None\nself.active_brackets = []  # list of SHBracketManager objects\nself.traj = []\nself.runtime = []\nself.history = []\nself.start = None\n# Dask variables\nif n_workers is None and client is None:\nraise ValueError(\"Need to specify either 'n_workers'(&gt;0) or 'client' (a Dask client)!\")\nif client is not None and isinstance(client, Client):\nself.client = client\nself.n_workers = len(client.ncores())\nelse:\nself.n_workers = n_workers\nif self.n_workers &gt; 1:\nself.client = Client(\nn_workers=self.n_workers, processes=True, threads_per_worker=1, scheduler_port=0\n)  # port 0 makes Dask select a random free port\nelse:\nself.client = None\nself.futures = []\nself.shared_data = None\n# Initializing DE subpopulations\nself._get_pop_sizes()\nself._init_subpop()\n# Misc.\nself.available_gpus = None\nself.gpu_usage = None\nself.single_node_with_gpus = None\n</code></pre>"},{"location":"references/dehb/#dehb.optimizers.dehb.DEHB.__getstate__","title":"<code>__getstate__()</code>","text":"<p>Allows the object to picklable while having Dask client as a class attribute.</p> Source code in <code>src/dehb/optimizers/dehb.py</code> <pre><code>def __getstate__(self):\n\"\"\" Allows the object to picklable while having Dask client as a class attribute.\n    \"\"\"\nd = dict(self.__dict__)\nd[\"client\"] = None  # hack to allow Dask client to be a class attribute\nd[\"logger\"] = None  # hack to allow logger object to be a class attribute\nreturn d\n</code></pre>"},{"location":"references/dehb/#dehb.optimizers.dehb.DEHB.__del__","title":"<code>__del__()</code>","text":"<p>Ensures a clean kill of the Dask client and frees up a port.</p> Source code in <code>src/dehb/optimizers/dehb.py</code> <pre><code>def __del__(self):\n\"\"\" Ensures a clean kill of the Dask client and frees up a port.\n    \"\"\"\nif hasattr(self, \"client\") and isinstance(self, Client):\nself.client.close()\n</code></pre>"},{"location":"references/dehb/#dehb.optimizers.dehb.DEHB.distribute_gpus","title":"<code>distribute_gpus()</code>","text":"<p>Function to create a GPU usage tracker dict.</p> <p>The idea is to extract the exact GPU device IDs available. During job submission, each submitted job is given a preference of a GPU device ID based on the GPU device with the least number of active running jobs. On retrieval of the result, this gpu usage dict is updated for the device ID that the finished job was mapped to.</p> Source code in <code>src/dehb/optimizers/dehb.py</code> <pre><code>def distribute_gpus(self):\n\"\"\" Function to create a GPU usage tracker dict.\n    The idea is to extract the exact GPU device IDs available. During job submission, each\n    submitted job is given a preference of a GPU device ID based on the GPU device with the\n    least number of active running jobs. On retrieval of the result, this gpu usage dict is\n    updated for the device ID that the finished job was mapped to.\n    \"\"\"\ntry:\navailable_gpus = os.environ[\"CUDA_VISIBLE_DEVICES\"]\navailable_gpus = available_gpus.strip().split(\",\")\nself.available_gpus = [int(_id) for _id in available_gpus]\nexcept KeyError as e:\nprint(\"Unable to find valid GPU devices. \"\n\"Environment variable {} not visible!\".format(str(e)))\nself.available_gpus = []\nself.gpu_usage = dict()\nfor _id in self.available_gpus:\nself.gpu_usage[_id] = 0\n</code></pre>"},{"location":"references/dehb/#dehb.optimizers.dehb.DEHB.clean_inactive_brackets","title":"<code>clean_inactive_brackets()</code>","text":"<p>Removes brackets from the active list if it is done as communicated by Bracket Manager</p> Source code in <code>src/dehb/optimizers/dehb.py</code> <pre><code>def clean_inactive_brackets(self):\n\"\"\" Removes brackets from the active list if it is done as communicated by Bracket Manager\n    \"\"\"\nif len(self.active_brackets) == 0:\nreturn\nself.active_brackets = [\nbracket for bracket in self.active_brackets if ~bracket.is_bracket_done()\n]\nreturn\n</code></pre>"},{"location":"references/dehb/#dehb.optimizers.dehb.DEHB.is_worker_available","title":"<code>is_worker_available(verbose=False)</code>","text":"<p>Checks if at least one worker is available to run a job</p> Source code in <code>src/dehb/optimizers/dehb.py</code> <pre><code>def is_worker_available(self, verbose=False):\n\"\"\" Checks if at least one worker is available to run a job\n    \"\"\"\nif self.n_workers == 1 or self.client is None or not isinstance(self.client, Client):\n# in the synchronous case, one worker is always available\nreturn True\n# checks the absolute number of workers mapped to the client scheduler\n# client.ncores() should return a dict with the keys as unique addresses to these workers\n# treating the number of available workers in this manner\nworkers = self._get_worker_count()  # len(self.client.ncores())\nif len(self.futures) &gt;= workers:\n# pause/wait if active worker count greater allocated workers\nreturn False\nreturn True\n</code></pre>"},{"location":"references/dehb/#dehb.optimizers.dehb.DEHB.submit_job","title":"<code>submit_job(job_info, **kwargs)</code>","text":"<p>Asks a free worker to run the objective function on config and budget</p> Source code in <code>src/dehb/optimizers/dehb.py</code> <pre><code>def submit_job(self, job_info, **kwargs):\n\"\"\" Asks a free worker to run the objective function on config and budget\n    \"\"\"\njob_info[\"kwargs\"] = self.shared_data if self.shared_data is not None else kwargs\n# submit to to Dask client\nif self.n_workers &gt; 1 or isinstance(self.client, Client):\nif self.single_node_with_gpus:\n# managing GPU allocation for the job to be submitted\njob_info.update({\"gpu_devices\": self._get_gpu_id_with_low_load()})\nself.futures.append(\nself.client.submit(self._f_objective, job_info)\n)\nelse:\n# skipping scheduling to Dask worker to avoid added overheads in the synchronous case\nself.futures.append(self._f_objective(job_info))\n# pass information of job submission to Bracket Manager\nfor bracket in self.active_brackets:\nif bracket.bracket_id == job_info['bracket_id']:\n# registering is IMPORTANT for Bracket Manager to perform SH\nbracket.register_job(job_info['budget'])\nbreak\n</code></pre>"},{"location":"references/dehb/#dehb.optimizers.dehb.DEHB.run","title":"<code>run(fevals=None, brackets=None, total_cost=None, single_node_with_gpus=False, verbose=False, debug=False, save_intermediate=True, save_history=True, name=None, **kwargs)</code>","text":"<p>Main interface to run optimization by DEHB</p> <p>This function waits on workers and if a worker is free, asks for a configuration and a budget to evaluate on and submits it to the worker. In each loop, it checks if a job is complete, fetches the results, carries the necessary processing of it asynchronously to the worker computations.</p> <p>The duration of the DEHB run can be controlled by specifying one of 3 parameters. If more than one are specified, DEHB selects only one in the priority order (high to low): 1) Number of function evaluations (fevals) 2) Number of Successive Halving brackets run under Hyperband (brackets) 3) Total computational cost (in seconds) aggregated by all function evaluations (total_cost)</p> Source code in <code>src/dehb/optimizers/dehb.py</code> <pre><code>@logger.catch\ndef run(self, fevals=None, brackets=None, total_cost=None, single_node_with_gpus=False,\nverbose=False, debug=False, save_intermediate=True, save_history=True, name=None, **kwargs):\n\"\"\" Main interface to run optimization by DEHB\n    This function waits on workers and if a worker is free, asks for a configuration and a\n    budget to evaluate on and submits it to the worker. In each loop, it checks if a job\n    is complete, fetches the results, carries the necessary processing of it asynchronously\n    to the worker computations.\n    The duration of the DEHB run can be controlled by specifying one of 3 parameters. If more\n    than one are specified, DEHB selects only one in the priority order (high to low):\n    1) Number of function evaluations (fevals)\n    2) Number of Successive Halving brackets run under Hyperband (brackets)\n    3) Total computational cost (in seconds) aggregated by all function evaluations (total_cost)\n    \"\"\"\n# checks if a Dask client exists\nif len(kwargs) &gt; 0 and self.n_workers &gt; 1 and isinstance(self.client, Client):\n# broadcasts all additional data passed as **kwargs to all client workers\n# this reduces overload in the client-worker communication by not having to\n# serialize the redundant data used by all workers for every job\nself.shared_data = self.client.scatter(kwargs, broadcast=True)\n# allows each worker to be mapped to a different GPU when running on a single node\n# where all available GPUs are accessible\nself.single_node_with_gpus = single_node_with_gpus\nif self.single_node_with_gpus:\nself.distribute_gpus()\nself.start = time.time()\nif verbose:\nprint(\"\\nLogging at {} for optimization starting at {}\\n\".format(\nos.path.join(os.getcwd(), self.log_filename),\ntime.strftime(\"%x %X %Z\", time.localtime(self.start))\n))\nif debug:\nlogger.configure(handlers=[{\"sink\": sys.stdout}])\nwhile True:\nif self._is_run_budget_exhausted(fevals, brackets, total_cost):\nbreak\nif self.is_worker_available():\njob_info = self._get_next_job()\nif brackets is not None and job_info['bracket_id'] &gt;= brackets:\n# ignore submission and only collect results\n# when brackets are chosen as run budget, an extra bracket is created\n# since iteration_counter is incremented in _get_next_job() and then checked\n# in _is_run_budget_exhausted(), therefore, need to skip suggestions\n# coming from the extra allocated bracket\n# _is_run_budget_exhausted() will not return True until all the lower brackets\n# have finished computation and returned its results\npass\nelse:\nif self.n_workers &gt; 1 or isinstance(self.client, Client):\nself.logger.debug(\"{}/{} worker(s) available.\".format(\nself._get_worker_count() - len(self.futures), self._get_worker_count()\n))\n# submits job_info to a worker for execution\nself.submit_job(job_info, **kwargs)\nif verbose:\nbudget = job_info['budget']\nself._verbosity_runtime(fevals, brackets, total_cost)\nself.logger.info(\n\"Evaluating a configuration with budget {} under \"\n\"bracket ID {}\".format(budget, job_info['bracket_id'])\n)\nself.logger.info(\n\"Best score seen/Incumbent score: {}\".format(self.inc_score)\n)\nself._verbosity_debug()\nself._fetch_results_from_workers()\nif save_intermediate and self.inc_config is not None:\nself._save_incumbent(name)\nif save_history and self.history is not None:\nself._save_history(name)\nself.clean_inactive_brackets()\n# end of while\nif verbose and len(self.futures) &gt; 0:\nself.logger.info(\n\"DEHB optimisation over! Waiting to collect results from workers running...\"\n)\nwhile len(self.futures) &gt; 0:\nself._fetch_results_from_workers()\nif save_intermediate and self.inc_config is not None:\nself._save_incumbent(name)\nif save_history and self.history is not None:\nself._save_history(name)\ntime.sleep(0.05)  # waiting 50ms\nif verbose:\ntime_taken = time.time() - self.start\nself.logger.info(\"End of optimisation! Total duration: {}; Total fevals: {}\\n\".format(\ntime_taken, len(self.traj)\n))\nself.logger.info(\"Incumbent score: {}\".format(self.inc_score))\nself.logger.info(\"Incumbent config: \")\nif self.configspace:\nconfig = self.vector_to_configspace(self.inc_config)\nfor k, v in config.get_dictionary().items():\nself.logger.info(\"{}: {}\".format(k, v))\nelse:\nself.logger.info(\"{}\".format(self.inc_config))\nself._save_incumbent(name)\nself._save_history(name)\nreturn np.array(self.traj), np.array(self.runtime), np.array(self.history, dtype=object)\n</code></pre>"}]}