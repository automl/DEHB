{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to DEHB's documentation!","text":""},{"location":"#introduction","title":"Introduction","text":"<p><code>dehb</code> is a python package implementing the DEHB algorithm. It offers an intuitive interface to optimize user-defined problems using DEHB.</p> <p>This documentation explains how to use <code>dehb</code> and demonstrates its features. In the following section you will be guided how to install the <code>dehb</code> package and how to use it in your own projects. Examples with more hands-on material can be found in the examples folder.</p>"},{"location":"#installation","title":"Installation","text":"<p>To start using the <code>dehb</code> package, you can install it via pip. You can either install the package right from git or install it as an editable package to modify the code and rerun your experiments:</p> <pre><code># Install from pypi\npip install dehb\n</code></pre> <p>From Source</p> <p>To install directly from from source</p> <pre><code>git clone https://github.com/automl/DEHB.git\npip install -e DEHB  # -e stands for editable, lets you modify the code and rerun things\n</code></pre>"},{"location":"#contributing","title":"Contributing","text":"<p>Please have a look at our contributing guidelines.</p>"},{"location":"#to-cite-the-paper-or-code","title":"To cite the paper or code","text":"<p>If you use DEHB in one of your research projects, please cite our paper(s): <pre><code>@inproceedings{awad-ijcai21,\n  author    = {N. Awad and N. Mallik and F. Hutter},\n  title     = {{DEHB}: Evolutionary Hyberband for Scalable, Robust and Efficient Hyperparameter Optimization},\n  pages     = {2147--2153},\n  booktitle = {Proceedings of the Thirtieth International Joint Conference on\n               Artificial Intelligence, {IJCAI-21}},\n  publisher = {ijcai.org},\n  editor    = {Z. Zhou},\n  year      = {2021}\n}\n</code></pre></p>"},{"location":"getting_started/parallel/","title":"Parallel","text":""},{"location":"getting_started/parallel/#running-dehb-in-a-parallel-setting","title":"Running DEHB in a parallel setting","text":"<p>DEHB has been designed to interface a Dask client. DEHB can either create a Dask client during instantiation and close/kill the client during garbage collection.  Or a client can be passed as an argument during instantiation.</p> <ul> <li>Setting <code>n_workers</code> during instantiation \\     If set to <code>1</code> (default) then the entire process is a sequential run without invoking Dask. \\     If set to <code>&gt;1</code> then a Dask Client is initialized with as many workers as <code>n_workers</code>. \\     This parameter is ignored if <code>client</code> is not None.</li> <li>Setting <code>client</code> during instantiation \\     When <code>None</code> (default), a Dask client is created using <code>n_workers</code> specified. \\     Else, any custom-configured Dask Client can be created and passed as the <code>client</code> argument to DEHB.</li> </ul>"},{"location":"getting_started/parallel/#using-gpus-in-a-parallel-run","title":"Using GPUs in a parallel run","text":"<p>Certain target function evaluations (especially for Deep Learning) require computations to be  carried out on GPUs. The GPU devices are often ordered by device ID and if not configured, all  spawned worker processes access these devices in the same order and can either run out of memory or not exhibit parallelism.</p> <p>For <code>n_workers&gt;1</code> and when running on a single node (or local), the <code>single_node_with_gpus</code> can be  passed to the <code>run()</code> call to DEHB. Setting it to <code>False</code> (default) has no effect on the default setup  of the machine. Setting it to <code>True</code> will reorder the GPU device IDs dynamically by setting the environment  variable <code>CUDA_VISIBLE_DEVICES</code> for each worker process executing a target function evaluation. The re-ordering  is done in a manner that the first priority device is the one with the least number of active jobs assigned  to it by that DEHB run.</p> <p>To run the PyTorch MNIST example on a single node using 2 workers: <pre><code>python examples/03_pytorch_mnist_hpo.py \\\n    --min_budget 1 \\\n    --max_budget 3 \\\n    --runtime 60 \\\n    --n_workers 2 \\\n    --single_node_with_gpus \\\n    --verbose\n</code></pre></p>"},{"location":"getting_started/parallel/#multi-node-runs","title":"Multi-node runs","text":"<p>Multi-node parallelism is often contingent on the cluster setup to be deployed on. Dask provides useful  frameworks to interface various cluster designs. As long as the <code>client</code> passed to DEHB during  instantiation is of type <code>dask.distributed.Client</code>, DEHB can interact with this client and  distribute its optimization process in a parallel manner. </p> <p>For instance, <code>Dask-CLI</code> can be used to create a <code>dask-scheduler</code> which can dump its connection  details to a file on a cluster node accessible to all processes. Multiple <code>dask-worker</code> can then be created to interface the <code>dask-scheduler</code> by connecting to the details read from the file dumped. Each dask-worker can be triggered on any remote machine. Each worker can be configured as required,  including mapping to specific GPU devices. </p> <p>Some helper scripts can be found here, that can be used as a reference to run DEHB in a multi-node  manner on clusters managed by SLURM. (not expected to work off-the-shelf)</p> <p>To run the PyTorch MNIST example on a multi-node setup using 4 workers: <pre><code>bash utils/run_dask_setup.sh \\\n    -n 4 \\\n    -f dask_dump/scheduler.json \\   # This is how the workers will be discovered by DEHB\n    -e env_name\n\n# Make sure to sleep to allow the workers to setup properly\nsleep 5\n\npython examples/03_pytorch_mnist_hpo.py \\\n    --min_budget 1 \\\n    --max_budget 3 \\\n    --runtime 60 \\\n    --scheduler_file dask_dump/scheduler.json \\\n    --verbose\n</code></pre></p>"},{"location":"getting_started/single_worker/","title":"Single Worker","text":""},{"location":"getting_started/single_worker/#basic-single-worker-setup","title":"Basic single worker setup","text":"<p>A basic setup for optimizing can be done as follows. Please note, that this is example should solely show a simple setup of <code>dehb</code>. More in-depth examples can be found in the examples folder. First we need to setup a <code>ConfigurationSpace</code>, from which Configurations will be sampled:</p> Configuration Space<pre><code>from ConfigSpace import ConfigurationSpace, Configuration\n\ncs = ConfigurationSpace({\"x0\": (3.0, 10.0), \"x1\": [\"red\", \"green\"]})\nprint(cs)\n</code></pre> <pre><code>Configuration space object:\n  Hyperparameters:\n    x0, Type: UniformFloat, Range: [3.0, 10.0], Default: 6.5\n    x1, Type: Categorical, Choices: {red, green}, Default: red\n</code></pre> <p>Next, we need an <code>object_function</code>, which we are aiming to optimize: Configuration Space<pre><code>import numpy as np\n\ndef objective_function(x: Configuration, budget: float, **kwargs):\n    # Replace this with your actual objective value (y) and cost.\n    cost = (10 if x[\"x1\"] == \"red\" else 100) + budget\n    y = x[\"x0\"] + np.random.uniform()\n    return {\"fitness\": y, \"cost\": x[\"x0\"]}\n\nsample_config = cs.sample_configuration()\nprint(sample_config)\n\nresult = objective_function(sample_config, budget=10)\nprint(result)\n</code></pre> <pre><code>Configuration(values={\n  'x0': 7.06732300205754,\n  'x1': 'green',\n})\n{'fitness': 7.30944485578766, 'cost': 7.06732300205754}\n</code></pre> </p> <p>Finally, we can setup our optimizer and run DEHB:</p> Configuration Space<pre><code>from dehb import DEHB\n\ndim = len(cs.get_hyperparameters())\noptimizer = DEHB(\n    f=objective_function,\n    cs=cs,\n    dimensions=dim,\n    min_budget=3,\n    max_budget=27,\n    eta=3,\n    n_workers=1,\n    output_path=\"./logs\",\n)\n\n# Run optimization for 1 bracket. Output files will be saved to ./logs\ntraj, runtime, history = optimizer.run(brackets=1, verbose=True)\nconfig, fitness, runtime, budget, _ = history[0]\nprint(\"config\", config)\nprint(\"fitness\", fitness)\nprint(\"runtime\", runtime)\nprint(\"budget\", budget)\n</code></pre> <pre><code>config [0.5830543458723856, 0.5]\nfitness 7.11786132340316\nruntime 7.081380421106699\nbudget 3.0\n</code></pre>"},{"location":"references/bracket_manager/","title":"Bracket manager","text":""},{"location":"references/bracket_manager/#dehb.utils.bracket_manager.SHBracketManager","title":"<code>SHBracketManager(n_configs, budgets, bracket_id=None)</code>","text":"<p>             Bases: <code>object</code></p> <p>Synchronous Successive Halving utilities</p> Source code in <code>src/dehb/utils/bracket_manager.py</code> <pre><code>def __init__(self, n_configs, budgets, bracket_id=None):\n    assert len(n_configs) == len(budgets)\n    self.n_configs = n_configs\n    self.budgets = budgets\n    self.bracket_id = bracket_id\n    self.sh_bracket = {}\n    self._sh_bracket = {}\n    self._config_map = {}\n    for i, budget in enumerate(budgets):\n        # sh_bracket keeps track of jobs/configs that are still to be scheduled/allocatted\n        # _sh_bracket keeps track of jobs/configs that have been run and results retrieved for\n        # (sh_bracket[i] + _sh_bracket[i]) == n_configs[i] is when no jobs have been scheduled\n        #   or all jobs for that budget/rung are over\n        # (sh_bracket[i] + _sh_bracket[i]) &lt; n_configs[i] indicates a job has been scheduled\n        #   and is queued/running and the bracket needs to be paused till results are retrieved\n        self.sh_bracket[budget] = n_configs[i]  # each scheduled job does -= 1\n        self._sh_bracket[budget] = 0  # each retrieved job does +=1\n    self.n_rungs = len(budgets)\n    self.current_rung = 0\n</code></pre>"},{"location":"references/bracket_manager/#dehb.utils.bracket_manager.SHBracketManager.get_budget","title":"<code>get_budget(rung=None)</code>","text":"<p>Returns the exact budget that rung is pointing to.</p> <p>Returns current rung's budget if no rung is passed.</p> Source code in <code>src/dehb/utils/bracket_manager.py</code> <pre><code>def get_budget(self, rung=None):\n    \"\"\" Returns the exact budget that rung is pointing to.\n\n    Returns current rung's budget if no rung is passed.\n    \"\"\"\n    if rung is not None:\n        return self.budgets[rung]\n    return self.budgets[self.current_rung]\n</code></pre>"},{"location":"references/bracket_manager/#dehb.utils.bracket_manager.SHBracketManager.get_lower_budget_promotions","title":"<code>get_lower_budget_promotions(budget)</code>","text":"<p>Returns the immediate lower budget and the number of configs to be promoted from there</p> Source code in <code>src/dehb/utils/bracket_manager.py</code> <pre><code>def get_lower_budget_promotions(self, budget):\n    \"\"\" Returns the immediate lower budget and the number of configs to be promoted from there\n    \"\"\"\n    assert budget in self.budgets\n    rung = np.where(budget == self.budgets)[0][0]\n    prev_rung = np.clip(rung - 1, a_min=0, a_max=self.n_rungs-1)\n    lower_budget = self.budgets[prev_rung]\n    num_promote_configs = self.n_configs[rung]\n    return lower_budget, num_promote_configs\n</code></pre>"},{"location":"references/bracket_manager/#dehb.utils.bracket_manager.SHBracketManager.get_next_job_budget","title":"<code>get_next_job_budget()</code>","text":"<p>Returns the budget that will be selected if current_rung is incremented by 1</p> Source code in <code>src/dehb/utils/bracket_manager.py</code> <pre><code>def get_next_job_budget(self):\n    \"\"\" Returns the budget that will be selected if current_rung is incremented by 1\n    \"\"\"\n    if self.sh_bracket[self.get_budget()] &gt; 0:\n        # the current rung still has unallocated jobs (&gt;0)\n        return self.get_budget()\n    else:\n        # the current rung has no more jobs to allocate, increment it\n        rung = (self.current_rung + 1) % self.n_rungs\n        if self.sh_bracket[self.get_budget(rung)] &gt; 0:\n            # the incremented rung has unallocated jobs (&gt;0)\n            return self.get_budget(rung)\n        else:\n            # all jobs for this bracket has been allocated/bracket is complete\n            # no more budgets to evaluate and can return None\n            pass\n        return None\n</code></pre>"},{"location":"references/bracket_manager/#dehb.utils.bracket_manager.SHBracketManager.register_job","title":"<code>register_job(budget)</code>","text":"<p>Registers the allocation of a configuration for the budget and updates current rung</p> <p>This function must be called when scheduling a job in order to allow the bracket manager to continue job and budget allocation without waiting for jobs to finish and return results necessarily. This feature can be leveraged to run brackets asynchronously.</p> Source code in <code>src/dehb/utils/bracket_manager.py</code> <pre><code>def register_job(self, budget):\n    \"\"\" Registers the allocation of a configuration for the budget and updates current rung\n\n    This function must be called when scheduling a job in order to allow the bracket manager\n    to continue job and budget allocation without waiting for jobs to finish and return\n    results necessarily. This feature can be leveraged to run brackets asynchronously.\n    \"\"\"\n    assert budget in self.budgets\n    assert self.sh_bracket[budget] &gt; 0\n    self.sh_bracket[budget] -= 1\n    if not self._is_rung_pending(self.current_rung):\n        # increment current rung if no jobs left in the rung\n        self.current_rung = (self.current_rung + 1) % self.n_rungs\n</code></pre>"},{"location":"references/bracket_manager/#dehb.utils.bracket_manager.SHBracketManager.complete_job","title":"<code>complete_job(budget)</code>","text":"<p>Notifies the bracket that a job for a budget has been completed</p> <p>This function must be called when a config for a budget has finished evaluation to inform the Bracket Manager that no job needs to be waited for and the next rung can begin for the synchronous Successive Halving case.</p> Source code in <code>src/dehb/utils/bracket_manager.py</code> <pre><code>def complete_job(self, budget):\n    \"\"\" Notifies the bracket that a job for a budget has been completed\n\n    This function must be called when a config for a budget has finished evaluation to inform\n    the Bracket Manager that no job needs to be waited for and the next rung can begin for the\n    synchronous Successive Halving case.\n    \"\"\"\n    assert budget in self.budgets\n    _max_configs = self.n_configs[list(self.budgets).index(budget)]\n    assert self._sh_bracket[budget] &lt; _max_configs\n    self._sh_bracket[budget] += 1\n</code></pre>"},{"location":"references/bracket_manager/#dehb.utils.bracket_manager.SHBracketManager.previous_rung_waits","title":"<code>previous_rung_waits()</code>","text":"<p>Returns True if none of the rungs &lt; current rung is waiting for results</p> Source code in <code>src/dehb/utils/bracket_manager.py</code> <pre><code>def previous_rung_waits(self):\n    \"\"\" Returns True if none of the rungs &lt; current rung is waiting for results\n    \"\"\"\n    for rung in range(self.current_rung):\n        if self._is_rung_waiting(rung) and not self._is_rung_pending(rung):\n            return True\n    return False\n</code></pre>"},{"location":"references/bracket_manager/#dehb.utils.bracket_manager.SHBracketManager.is_bracket_done","title":"<code>is_bracket_done()</code>","text":"<p>Returns True if all configs in all rungs in the bracket have been allocated</p> Source code in <code>src/dehb/utils/bracket_manager.py</code> <pre><code>def is_bracket_done(self):\n    \"\"\" Returns True if all configs in all rungs in the bracket have been allocated\n    \"\"\"\n    return ~self.is_pending() and ~self.is_waiting()\n</code></pre>"},{"location":"references/bracket_manager/#dehb.utils.bracket_manager.SHBracketManager.is_pending","title":"<code>is_pending()</code>","text":"<p>Returns True if any of the rungs/budgets have still a configuration to submit</p> Source code in <code>src/dehb/utils/bracket_manager.py</code> <pre><code>def is_pending(self):\n    \"\"\" Returns True if any of the rungs/budgets have still a configuration to submit\n    \"\"\"\n    return np.any([self._is_rung_pending(i) &gt; 0 for i, _ in enumerate(self.budgets)])\n</code></pre>"},{"location":"references/bracket_manager/#dehb.utils.bracket_manager.SHBracketManager.is_waiting","title":"<code>is_waiting()</code>","text":"<p>Returns True if any of the rungs/budgets have a configuration pending/running</p> Source code in <code>src/dehb/utils/bracket_manager.py</code> <pre><code>def is_waiting(self):\n    \"\"\" Returns True if any of the rungs/budgets have a configuration pending/running\n    \"\"\"\n    return np.any([self._is_rung_waiting(i) &gt; 0 for i, _ in enumerate(self.budgets)])\n</code></pre>"},{"location":"references/de/","title":"DE","text":""},{"location":"references/de/#dehb.optimizers.de.DEBase","title":"<code>DEBase(cs=None, f=None, dimensions=None, pop_size=None, max_age=None, mutation_factor=None, crossover_prob=None, strategy=None, budget=None, boundary_fix_type='random', **kwargs)</code>","text":"<p>Base class for Differential Evolution</p> Source code in <code>src/dehb/optimizers/de.py</code> <pre><code>def __init__(self, cs=None, f=None, dimensions=None, pop_size=None, max_age=None,\n             mutation_factor=None, crossover_prob=None, strategy=None, budget=None,\n             boundary_fix_type='random', **kwargs):\n    # Benchmark related variables\n    self.cs = cs\n    self.f = f\n    if dimensions is None and self.cs is not None:\n        self.dimensions = len(self.cs.get_hyperparameters())\n    else:\n        self.dimensions = dimensions\n\n    # DE related variables\n    self.pop_size = pop_size\n    self.max_age = max_age\n    self.mutation_factor = mutation_factor\n    self.crossover_prob = crossover_prob\n    self.strategy = strategy\n    self.budget = budget\n    self.fix_type = boundary_fix_type\n\n    # Miscellaneous\n    self.configspace = True if isinstance(self.cs, ConfigSpace.ConfigurationSpace) else False\n    self.hps = dict()\n    if self.configspace:\n        for i, hp in enumerate(cs.get_hyperparameters()):\n            # maps hyperparameter name to positional index in vector form\n            self.hps[hp.name] = i\n    self.output_path = kwargs['output_path'] if 'output_path' in kwargs else './'\n    os.makedirs(self.output_path, exist_ok=True)\n\n    # Global trackers\n    self.inc_score = np.inf\n    self.inc_config = None\n    self.population = None\n    self.fitness = None\n    self.age = None\n    self.history = []\n</code></pre>"},{"location":"references/de/#dehb.optimizers.de.DEBase.sample_population","title":"<code>sample_population(size=3, alt_pop=None)</code>","text":"<p>Samples 'size' individuals</p> <p>If alt_pop is None or a list/array of None, sample from own population Else sample from the specified alternate population (alt_pop)</p> Source code in <code>src/dehb/optimizers/de.py</code> <pre><code>def sample_population(self, size: int = 3, alt_pop: List = None) -&gt; List:\n    '''Samples 'size' individuals\n\n    If alt_pop is None or a list/array of None, sample from own population\n    Else sample from the specified alternate population (alt_pop)\n    '''\n    if isinstance(alt_pop, list) or isinstance(alt_pop, np.ndarray):\n        idx = [indv is None for indv in alt_pop]\n        if any(idx):\n            selection = np.random.choice(np.arange(len(self.population)), size, replace=False)\n            return self.population[selection]\n        else:\n            if len(alt_pop) &lt; 3:\n                alt_pop = np.vstack((alt_pop, self.population))\n            selection = np.random.choice(np.arange(len(alt_pop)), size, replace=False)\n            alt_pop = np.stack(alt_pop)\n            return alt_pop[selection]\n    else:\n        selection = np.random.choice(np.arange(len(self.population)), size, replace=False)\n        return self.population[selection]\n</code></pre>"},{"location":"references/de/#dehb.optimizers.de.DEBase.boundary_check","title":"<code>boundary_check(vector)</code>","text":"<p>Checks whether each of the dimensions of the input vector are within [0, 1]. If not, values of those dimensions are replaced with the type of fix selected.</p> <p>if fix_type == 'random', the values are replaced with a random sampling from (0,1) if fix_type == 'clip', the values are clipped to the closest limit from {0, 1}</p>"},{"location":"references/de/#dehb.optimizers.de.DEBase.boundary_check--parameters","title":"Parameters","text":"<p>vector : array</p>"},{"location":"references/de/#dehb.optimizers.de.DEBase.boundary_check--returns","title":"Returns","text":"<p>array</p> Source code in <code>src/dehb/optimizers/de.py</code> <pre><code>def boundary_check(self, vector: np.array) -&gt; np.array:\n    '''\n    Checks whether each of the dimensions of the input vector are within [0, 1].\n    If not, values of those dimensions are replaced with the type of fix selected.\n\n    if fix_type == 'random', the values are replaced with a random sampling from (0,1)\n    if fix_type == 'clip', the values are clipped to the closest limit from {0, 1}\n\n    Parameters\n    ----------\n    vector : array\n\n    Returns\n    -------\n    array\n    '''\n    violations = np.where((vector &gt; 1) | (vector &lt; 0))[0]\n    if len(violations) == 0:\n        return vector\n    if self.fix_type == 'random':\n        vector[violations] = np.random.uniform(low=0.0, high=1.0, size=len(violations))\n    else:\n        vector[violations] = np.clip(vector[violations], a_min=0, a_max=1)\n    return vector\n</code></pre>"},{"location":"references/de/#dehb.optimizers.de.DEBase.vector_to_configspace","title":"<code>vector_to_configspace(vector)</code>","text":"<p>Converts numpy array to ConfigSpace object</p> <p>Works when self.cs is a ConfigSpace object and the input vector is in the domain [0, 1].</p> Source code in <code>src/dehb/optimizers/de.py</code> <pre><code>def vector_to_configspace(self, vector: np.array) -&gt; ConfigSpace.Configuration:\n    '''Converts numpy array to ConfigSpace object\n\n    Works when self.cs is a ConfigSpace object and the input vector is in the domain [0, 1].\n    '''\n    # creates a ConfigSpace object dict with all hyperparameters present, the inactive too\n    new_config = ConfigSpace.util.impute_inactive_values(\n        self.cs.sample_configuration()\n    ).get_dictionary()\n    # iterates over all hyperparameters and normalizes each based on its type\n    for i, hyper in enumerate(self.cs.get_hyperparameters()):\n        if type(hyper) == ConfigSpace.OrdinalHyperparameter:\n            ranges = np.arange(start=0, stop=1, step=1/len(hyper.sequence))\n            param_value = hyper.sequence[np.where((vector[i] &lt; ranges) == False)[0][-1]]\n        elif type(hyper) == ConfigSpace.CategoricalHyperparameter:\n            ranges = np.arange(start=0, stop=1, step=1/len(hyper.choices))\n            param_value = hyper.choices[np.where((vector[i] &lt; ranges) == False)[0][-1]]\n        elif type(hyper) == ConfigSpace.Constant:\n            param_value = hyper.default_value\n        else:  # handles UniformFloatHyperparameter &amp; UniformIntegerHyperparameter\n            # rescaling continuous values\n            if hyper.log:\n                log_range = np.log(hyper.upper) - np.log(hyper.lower)\n                param_value = np.exp(np.log(hyper.lower) + vector[i] * log_range)\n            else:\n                param_value = hyper.lower + (hyper.upper - hyper.lower) * vector[i]\n            if type(hyper) == ConfigSpace.UniformIntegerHyperparameter:\n                param_value = int(np.round(param_value))  # converting to discrete (int)\n            else:\n                param_value = float(param_value)\n        new_config[hyper.name] = param_value\n    # the mapping from unit hypercube to the actual config space may lead to illegal\n    # configurations based on conditions defined, which need to be deactivated/removed\n    new_config = ConfigSpace.util.deactivate_inactive_hyperparameters(\n        configuration = new_config, configuration_space=self.cs\n    )\n    return new_config\n</code></pre>"},{"location":"references/de/#dehb.optimizers.de.DEBase.configspace_to_vector","title":"<code>configspace_to_vector(config)</code>","text":"<p>Converts ConfigSpace object to numpy array scaled to [0,1]</p> <p>Works when self.cs is a ConfigSpace object and the input config is a ConfigSpace object. Handles conditional spaces implicitly by replacing illegal parameters with default values to maintain the dimensionality of the vector.</p> Source code in <code>src/dehb/optimizers/de.py</code> <pre><code>def configspace_to_vector(self, config: ConfigSpace.Configuration) -&gt; np.array:\n    '''Converts ConfigSpace object to numpy array scaled to [0,1]\n\n    Works when self.cs is a ConfigSpace object and the input config is a ConfigSpace object.\n    Handles conditional spaces implicitly by replacing illegal parameters with default values\n    to maintain the dimensionality of the vector.\n    '''\n    # the imputation replaces illegal parameter values with their default\n    config = ConfigSpace.util.impute_inactive_values(config)\n    dimensions = len(self.cs.get_hyperparameters())\n    vector = [np.nan for i in range(dimensions)]\n    for name in config:\n        i = self.hps[name]\n        hyper = self.cs.get_hyperparameter(name)\n        if type(hyper) == ConfigSpace.OrdinalHyperparameter:\n            nlevels = len(hyper.sequence)\n            vector[i] = hyper.sequence.index(config[name]) / nlevels\n        elif type(hyper) == ConfigSpace.CategoricalHyperparameter:\n            nlevels = len(hyper.choices)\n            vector[i] = hyper.choices.index(config[name]) / nlevels\n        elif type(hyper) == ConfigSpace.Constant:\n            vector[i] = 0 # set constant to 0, so that it wont be affected by mutation\n        else:\n            bounds = (hyper.lower, hyper.upper)\n            param_value = config[name]\n            if hyper.log:\n                vector[i] = np.log(param_value / bounds[0]) / np.log(bounds[1] / bounds[0])\n            else:\n                vector[i] = (config[name] - bounds[0]) / (bounds[1] - bounds[0])\n    return np.array(vector)\n</code></pre>"},{"location":"references/de/#dehb.optimizers.de.DE","title":"<code>DE(cs=None, f=None, dimensions=None, pop_size=20, max_age=np.inf, mutation_factor=None, crossover_prob=None, strategy='rand1_bin', budget=None, encoding=False, dim_map=None, **kwargs)</code>","text":"<p>             Bases: <code>DEBase</code></p> Source code in <code>src/dehb/optimizers/de.py</code> <pre><code>def __init__(self, cs=None, f=None, dimensions=None, pop_size=20, max_age=np.inf,\n             mutation_factor=None, crossover_prob=None, strategy='rand1_bin',\n             budget=None, encoding=False, dim_map=None, **kwargs):\n    super().__init__(cs=cs, f=f, dimensions=dimensions, pop_size=pop_size, max_age=max_age,\n                     mutation_factor=mutation_factor, crossover_prob=crossover_prob,\n                     strategy=strategy, budget=budget, **kwargs)\n    if self.strategy is not None:\n        self.mutation_strategy = self.strategy.split('_')[0]\n        self.crossover_strategy = self.strategy.split('_')[1]\n    else:\n        self.mutation_strategy = self.crossover_strategy = None\n    self.encoding = encoding\n    self.dim_map = dim_map\n    self._set_min_pop_size()\n</code></pre>"},{"location":"references/de/#dehb.optimizers.de.DE.__getstate__","title":"<code>__getstate__()</code>","text":"<p>Allows the object to picklable while having Dask client as a class attribute.</p> Source code in <code>src/dehb/optimizers/de.py</code> <pre><code>def __getstate__(self):\n    \"\"\" Allows the object to picklable while having Dask client as a class attribute.\n    \"\"\"\n    d = dict(self.__dict__)\n    d[\"client\"] = None  # hack to allow Dask client to be a class attribute\n    d[\"logger\"] = None  # hack to allow logger object to be a class attribute\n    return d\n</code></pre>"},{"location":"references/de/#dehb.optimizers.de.DE.__del__","title":"<code>__del__()</code>","text":"<p>Ensures a clean kill of the Dask client and frees up a port.</p> Source code in <code>src/dehb/optimizers/de.py</code> <pre><code>def __del__(self):\n    \"\"\" Ensures a clean kill of the Dask client and frees up a port.\n    \"\"\"\n    if hasattr(self, \"client\") and isinstance(self.client, Client):\n        self.client.close()\n</code></pre>"},{"location":"references/de/#dehb.optimizers.de.DE.init_eval_pop","title":"<code>init_eval_pop(budget=None, eval=True, **kwargs)</code>","text":"<p>Creates new population of 'pop_size' and evaluates individuals.</p> Source code in <code>src/dehb/optimizers/de.py</code> <pre><code>def init_eval_pop(self, budget=None, eval=True, **kwargs):\n    '''Creates new population of 'pop_size' and evaluates individuals.\n    '''\n    self.population = self.init_population(self.pop_size)\n    self.fitness = np.array([np.inf for i in range(self.pop_size)])\n    self.age = np.array([self.max_age] * self.pop_size)\n\n    traj = []\n    runtime = []\n    history = []\n\n    if not eval:\n        return traj, runtime, history\n\n    for i in range(self.pop_size):\n        config = self.population[i]\n        res = self.f_objective(config, budget, **kwargs)\n        self.fitness[i], cost = res[\"fitness\"], res[\"cost\"]\n        info = res[\"info\"] if \"info\" in res else dict()\n        if self.fitness[i] &lt; self.inc_score:\n            self.inc_score = self.fitness[i]\n            self.inc_config = config\n        traj.append(self.inc_score)\n        runtime.append(cost)\n        history.append((config.tolist(), float(self.fitness[i]), float(budget or 0), info))\n\n    return traj, runtime, history\n</code></pre>"},{"location":"references/de/#dehb.optimizers.de.DE.eval_pop","title":"<code>eval_pop(population=None, budget=None, **kwargs)</code>","text":"<p>Evaluates a population</p> <p>If population=None, the current population's fitness will be evaluated If population!=None, this population will be evaluated</p> Source code in <code>src/dehb/optimizers/de.py</code> <pre><code>def eval_pop(self, population=None, budget=None, **kwargs):\n    '''Evaluates a population\n\n    If population=None, the current population's fitness will be evaluated\n    If population!=None, this population will be evaluated\n    '''\n    pop = self.population if population is None else population\n    pop_size = self.pop_size if population is None else len(pop)\n    traj = []\n    runtime = []\n    history = []\n    fitnesses = []\n    costs = []\n    ages = []\n    for i in range(pop_size):\n        res = self.f_objective(pop[i], budget, **kwargs)\n        fitness, cost = res[\"fitness\"], res[\"cost\"]\n        info = res[\"info\"] if \"info\" in res else dict()\n        if population is None:\n            self.fitness[i] = fitness\n        if fitness &lt;= self.inc_score:\n            self.inc_score = fitness\n            self.inc_config = pop[i]\n        traj.append(self.inc_score)\n        runtime.append(cost)\n        history.append((pop[i].tolist(), float(fitness), float(budget or 0), info))\n        fitnesses.append(fitness)\n        costs.append(cost)\n        ages.append(self.max_age)\n    if population is None:\n        self.fitness = np.array(fitnesses)\n        return traj, runtime, history\n    else:\n        return traj, runtime, history, np.array(fitnesses), np.array(ages)\n</code></pre>"},{"location":"references/de/#dehb.optimizers.de.DE.mutation_rand1","title":"<code>mutation_rand1(r1, r2, r3)</code>","text":"<p>Performs the 'rand1' type of DE mutation</p> Source code in <code>src/dehb/optimizers/de.py</code> <pre><code>def mutation_rand1(self, r1, r2, r3):\n    '''Performs the 'rand1' type of DE mutation\n    '''\n    diff = r2 - r3\n    mutant = r1 + self.mutation_factor * diff\n    return mutant\n</code></pre>"},{"location":"references/de/#dehb.optimizers.de.DE.mutation_rand2","title":"<code>mutation_rand2(r1, r2, r3, r4, r5)</code>","text":"<p>Performs the 'rand2' type of DE mutation</p> Source code in <code>src/dehb/optimizers/de.py</code> <pre><code>def mutation_rand2(self, r1, r2, r3, r4, r5):\n    '''Performs the 'rand2' type of DE mutation\n    '''\n    diff1 = r2 - r3\n    diff2 = r4 - r5\n    mutant = r1 + self.mutation_factor * diff1 + self.mutation_factor * diff2\n    return mutant\n</code></pre>"},{"location":"references/de/#dehb.optimizers.de.DE.mutation","title":"<code>mutation(current=None, best=None, alt_pop=None)</code>","text":"<p>Performs DE mutation</p> Source code in <code>src/dehb/optimizers/de.py</code> <pre><code>def mutation(self, current=None, best=None, alt_pop=None):\n    '''Performs DE mutation\n    '''\n    if self.mutation_strategy == 'rand1':\n        r1, r2, r3 = self.sample_population(size=3, alt_pop=alt_pop)\n        mutant = self.mutation_rand1(r1, r2, r3)\n\n    elif self.mutation_strategy == 'rand2':\n        r1, r2, r3, r4, r5 = self.sample_population(size=5, alt_pop=alt_pop)\n        mutant = self.mutation_rand2(r1, r2, r3, r4, r5)\n\n    elif self.mutation_strategy == 'rand2dir':\n        r1, r2, r3 = self.sample_population(size=3, alt_pop=alt_pop)\n        mutant = self.mutation_rand2dir(r1, r2, r3)\n\n    elif self.mutation_strategy == 'best1':\n        r1, r2 = self.sample_population(size=2, alt_pop=alt_pop)\n        if best is None:\n            best = self.population[np.argmin(self.fitness)]\n        mutant = self.mutation_rand1(best, r1, r2)\n\n    elif self.mutation_strategy == 'best2':\n        r1, r2, r3, r4 = self.sample_population(size=4, alt_pop=alt_pop)\n        if best is None:\n            best = self.population[np.argmin(self.fitness)]\n        mutant = self.mutation_rand2(best, r1, r2, r3, r4)\n\n    elif self.mutation_strategy == 'currenttobest1':\n        r1, r2 = self.sample_population(size=2, alt_pop=alt_pop)\n        if best is None:\n            best = self.population[np.argmin(self.fitness)]\n        mutant = self.mutation_currenttobest1(current, best, r1, r2)\n\n    elif self.mutation_strategy == 'randtobest1':\n        r1, r2, r3 = self.sample_population(size=3, alt_pop=alt_pop)\n        if best is None:\n            best = self.population[np.argmin(self.fitness)]\n        mutant = self.mutation_currenttobest1(r1, best, r2, r3)\n\n    return mutant\n</code></pre>"},{"location":"references/de/#dehb.optimizers.de.DE.crossover_bin","title":"<code>crossover_bin(target, mutant)</code>","text":"<p>Performs the binomial crossover of DE</p> Source code in <code>src/dehb/optimizers/de.py</code> <pre><code>def crossover_bin(self, target, mutant):\n    '''Performs the binomial crossover of DE\n    '''\n    cross_points = np.random.rand(self.dimensions) &lt; self.crossover_prob\n    if not np.any(cross_points):\n        cross_points[np.random.randint(0, self.dimensions)] = True\n    offspring = np.where(cross_points, mutant, target)\n    return offspring\n</code></pre>"},{"location":"references/de/#dehb.optimizers.de.DE.crossover_exp","title":"<code>crossover_exp(target, mutant)</code>","text":"<p>Performs the exponential crossover of DE</p> Source code in <code>src/dehb/optimizers/de.py</code> <pre><code>def crossover_exp(self, target, mutant):\n    '''Performs the exponential crossover of DE\n    '''\n    n = np.random.randint(0, self.dimensions)\n    L = 0\n    while ((np.random.rand() &lt; self.crossover_prob) and L &lt; self.dimensions):\n        idx = (n+L) % self.dimensions\n        target[idx] = mutant[idx]\n        L = L + 1\n    return target\n</code></pre>"},{"location":"references/de/#dehb.optimizers.de.DE.crossover","title":"<code>crossover(target, mutant)</code>","text":"<p>Performs DE crossover</p> Source code in <code>src/dehb/optimizers/de.py</code> <pre><code>def crossover(self, target, mutant):\n    '''Performs DE crossover\n    '''\n    if self.crossover_strategy == 'bin':\n        offspring = self.crossover_bin(target, mutant)\n    elif self.crossover_strategy == 'exp':\n        offspring = self.crossover_exp(target, mutant)\n    return offspring\n</code></pre>"},{"location":"references/de/#dehb.optimizers.de.DE.selection","title":"<code>selection(trials, budget=None, **kwargs)</code>","text":"<p>Carries out a parent-offspring competition given a set of trial population</p> Source code in <code>src/dehb/optimizers/de.py</code> <pre><code>def selection(self, trials, budget=None, **kwargs):\n    '''Carries out a parent-offspring competition given a set of trial population\n    '''\n    traj = []\n    runtime = []\n    history = []\n    for i in range(len(trials)):\n        # evaluation of the newly created individuals\n        res = self.f_objective(trials[i], budget, **kwargs)\n        fitness, cost = res[\"fitness\"], res[\"cost\"]\n        info = res[\"info\"] if \"info\" in res else dict()\n        # selection -- competition between parent[i] -- child[i]\n        ## equality is important for landscape exploration\n        if fitness &lt;= self.fitness[i]:\n            self.population[i] = trials[i]\n            self.fitness[i] = fitness\n            # resetting age since new individual in the population\n            self.age[i] = self.max_age\n        else:\n            # decreasing age by 1 of parent who is better than offspring/trial\n            self.age[i] -= 1\n        # updation of global incumbent for trajectory\n        if self.fitness[i] &lt; self.inc_score:\n            self.inc_score = self.fitness[i]\n            self.inc_config = self.population[i]\n        traj.append(self.inc_score)\n        runtime.append(cost)\n        history.append((trials[i].tolist(), float(fitness), float(budget or 0), info))\n    return traj, runtime, history\n</code></pre>"},{"location":"references/de/#dehb.optimizers.de.DE.evolve_generation","title":"<code>evolve_generation(budget=None, best=None, alt_pop=None, **kwargs)</code>","text":"<p>Performs a complete DE evolution: mutation -&gt; crossover -&gt; selection</p> Source code in <code>src/dehb/optimizers/de.py</code> <pre><code>def evolve_generation(self, budget=None, best=None, alt_pop=None, **kwargs):\n    '''Performs a complete DE evolution: mutation -&gt; crossover -&gt; selection\n    '''\n    trials = []\n    for j in range(self.pop_size):\n        target = self.population[j]\n        donor = self.mutation(current=target, best=best, alt_pop=alt_pop)\n        trial = self.crossover(target, donor)\n        trial = self.boundary_check(trial)\n        trials.append(trial)\n    trials = np.array(trials)\n    traj, runtime, history = self.selection(trials, budget, **kwargs)\n    return traj, runtime, history\n</code></pre>"},{"location":"references/de/#dehb.optimizers.de.DE.sample_mutants","title":"<code>sample_mutants(size, population=None)</code>","text":"<p>Generates 'size' mutants from the population using rand1</p> Source code in <code>src/dehb/optimizers/de.py</code> <pre><code>def sample_mutants(self, size, population=None):\n    '''Generates 'size' mutants from the population using rand1\n    '''\n    if population is None:\n        population = self.population\n    elif len(population) &lt; 3:\n        population = np.vstack((self.population, population))\n\n    old_strategy = self.mutation_strategy\n    self.mutation_strategy = 'rand1'\n    mutants = np.random.uniform(low=0.0, high=1.0, size=(size, self.dimensions))\n    for i in range(size):\n        mutant = self.mutation(current=None, best=None, alt_pop=population)\n        mutants[i] = self.boundary_check(mutant)\n    self.mutation_strategy = old_strategy\n\n    return mutants\n</code></pre>"},{"location":"references/de/#dehb.optimizers.de.AsyncDE","title":"<code>AsyncDE(cs=None, f=None, dimensions=None, pop_size=None, max_age=np.inf, mutation_factor=None, crossover_prob=None, strategy='rand1_bin', budget=None, async_strategy='immediate', **kwargs)</code>","text":"<p>             Bases: <code>DE</code></p> <p>Extends DE to be Asynchronous with variations</p>"},{"location":"references/de/#dehb.optimizers.de.AsyncDE--parameters","title":"Parameters","text":"<p>async_strategy : str     'deferred' - target will be chosen sequentially from the population         the winner of the selection step will be included in the population only after         the entire population has had a selection step in that generation     'immediate' - target will be chosen sequentially from the population         the winner of the selection step is included in the population right away     'random' - target will be chosen randomly from the population for mutation-crossover         the winner of the selection step is included in the population right away     'worst' - the worst individual will be chosen as the target         the winner of the selection step is included in the population right away     {immediate, worst, random} implement Asynchronous-DE</p> Source code in <code>src/dehb/optimizers/de.py</code> <pre><code>def __init__(self, cs=None, f=None, dimensions=None, pop_size=None, max_age=np.inf,\n             mutation_factor=None, crossover_prob=None, strategy='rand1_bin',\n             budget=None, async_strategy='immediate', **kwargs):\n    '''Extends DE to be Asynchronous with variations\n\n    Parameters\n    ----------\n    async_strategy : str\n        'deferred' - target will be chosen sequentially from the population\n            the winner of the selection step will be included in the population only after\n            the entire population has had a selection step in that generation\n        'immediate' - target will be chosen sequentially from the population\n            the winner of the selection step is included in the population right away\n        'random' - target will be chosen randomly from the population for mutation-crossover\n            the winner of the selection step is included in the population right away\n        'worst' - the worst individual will be chosen as the target\n            the winner of the selection step is included in the population right away\n        {immediate, worst, random} implement Asynchronous-DE\n    '''\n    super().__init__(cs=cs, f=f, dimensions=dimensions, pop_size=pop_size, max_age=max_age,\n                     mutation_factor=mutation_factor, crossover_prob=crossover_prob,\n                     strategy=strategy, budget=budget, **kwargs)\n    if self.strategy is not None:\n        self.mutation_strategy = self.strategy.split('_')[0]\n        self.crossover_strategy = self.strategy.split('_')[1]\n    else:\n        self.mutation_strategy = self.crossover_strategy = None\n    self.async_strategy = async_strategy\n    assert self.async_strategy in ['immediate', 'random', 'worst', 'deferred'], \\\n            \"{} is not a valid choice for type of DE\".format(self.async_strategy)\n</code></pre>"},{"location":"references/de/#dehb.optimizers.de.AsyncDE.mutation","title":"<code>mutation(current=None, best=None, alt_pop=None)</code>","text":"<p>Performs DE mutation</p> Source code in <code>src/dehb/optimizers/de.py</code> <pre><code>def mutation(self, current=None, best=None, alt_pop=None):\n    '''Performs DE mutation\n    '''\n    if self.mutation_strategy == 'rand1':\n        r1, r2, r3 = self._sample_population(size=3, alt_pop=alt_pop, target=current)\n        mutant = self.mutation_rand1(r1, r2, r3)\n\n    elif self.mutation_strategy == 'rand2':\n        r1, r2, r3, r4, r5 = self._sample_population(size=5, alt_pop=alt_pop, target=current)\n        mutant = self.mutation_rand2(r1, r2, r3, r4, r5)\n\n    elif self.mutation_strategy == 'rand2dir':\n        r1, r2, r3 = self._sample_population(size=3, alt_pop=alt_pop, target=current)\n        mutant = self.mutation_rand2dir(r1, r2, r3)\n\n    elif self.mutation_strategy == 'best1':\n        r1, r2 = self._sample_population(size=2, alt_pop=alt_pop, target=current)\n        if best is None:\n            best = self.population[np.argmin(self.fitness)]\n        mutant = self.mutation_rand1(best, r1, r2)\n\n    elif self.mutation_strategy == 'best2':\n        r1, r2, r3, r4 = self._sample_population(size=4, alt_pop=alt_pop, target=current)\n        if best is None:\n            best = self.population[np.argmin(self.fitness)]\n        mutant = self.mutation_rand2(best, r1, r2, r3, r4)\n\n    elif self.mutation_strategy == 'currenttobest1':\n        r1, r2 = self._sample_population(size=2, alt_pop=alt_pop, target=current)\n        if best is None:\n            best = self.population[np.argmin(self.fitness)]\n        mutant = self.mutation_currenttobest1(current, best, r1, r2)\n\n    elif self.mutation_strategy == 'randtobest1':\n        r1, r2, r3 = self._sample_population(size=3, alt_pop=alt_pop, target=current)\n        if best is None:\n            best = self.population[np.argmin(self.fitness)]\n        mutant = self.mutation_currenttobest1(r1, best, r2, r3)\n\n    return mutant\n</code></pre>"},{"location":"references/de/#dehb.optimizers.de.AsyncDE.sample_mutants","title":"<code>sample_mutants(size, population=None)</code>","text":"<p>Samples 'size' mutants from the population</p> Source code in <code>src/dehb/optimizers/de.py</code> <pre><code>def sample_mutants(self, size, population=None):\n    '''Samples 'size' mutants from the population\n    '''\n    if population is None:\n        population = self.population\n\n    mutants = np.random.uniform(low=0.0, high=1.0, size=(size, self.dimensions))\n    for i in range(size):\n        j = np.random.choice(np.arange(len(population)))\n        mutant = self.mutation(current=population[j], best=self.inc_config, alt_pop=population)\n        mutants[i] = self.boundary_check(mutant)\n\n    return mutants\n</code></pre>"},{"location":"references/de/#dehb.optimizers.de.AsyncDE.evolve_generation","title":"<code>evolve_generation(budget=None, best=None, alt_pop=None, **kwargs)</code>","text":"<p>Performs a complete DE evolution, mutation -&gt; crossover -&gt; selection</p> Source code in <code>src/dehb/optimizers/de.py</code> <pre><code>def evolve_generation(self, budget=None, best=None, alt_pop=None, **kwargs):\n    '''Performs a complete DE evolution, mutation -&gt; crossover -&gt; selection\n    '''\n    traj = []\n    runtime = []\n    history = []\n\n    if self.async_strategy == 'deferred':\n        trials = []\n        for j in range(self.pop_size):\n            target = self.population[j]\n            donor = self.mutation(current=target, best=best, alt_pop=alt_pop)\n            trial = self.crossover(target, donor)\n            trial = self.boundary_check(trial)\n            trials.append(trial)\n        # selection takes place on a separate trial population only after\n        # one iteration through the population has taken place\n        trials = np.array(trials)\n        traj, runtime, history = self.selection(trials, budget, **kwargs)\n        return traj, runtime, history\n\n    elif self.async_strategy == 'immediate':\n        for i in range(self.pop_size):\n            target = self.population[i]\n            donor = self.mutation(current=target, best=best, alt_pop=alt_pop)\n            trial = self.crossover(target, donor)\n            trial = self.boundary_check(trial)\n            # evaluating a single trial population for the i-th individual\n            de_traj, de_runtime, de_history, fitnesses, costs = \\\n                self.eval_pop(trial.reshape(1, self.dimensions), budget=budget, **kwargs)\n            # one-vs-one selection\n            ## can replace the i-the population despite not completing one iteration\n            if fitnesses[0] &lt;= self.fitness[i]:\n                self.population[i] = trial\n                self.fitness[i] = fitnesses[0]\n            traj.extend(de_traj)\n            runtime.extend(de_runtime)\n            history.extend(de_history)\n        return traj, runtime, history\n\n    else:  # async_strategy == 'random' or async_strategy == 'worst':\n        for count in range(self.pop_size):\n            # choosing target individual\n            if self.async_strategy == 'random':\n                i = np.random.choice(np.arange(self.pop_size))\n            else:  # async_strategy == 'worst'\n                i = np.argsort(-self.fitness)[0]\n            target = self.population[i]\n            mutant = self.mutation(current=target, best=best, alt_pop=alt_pop)\n            trial = self.crossover(target, mutant)\n            trial = self.boundary_check(trial)\n            # evaluating a single trial population for the i-th individual\n            de_traj, de_runtime, de_history, fitnesses, costs = \\\n                self.eval_pop(trial.reshape(1, self.dimensions), budget=budget, **kwargs)\n            # one-vs-one selection\n            ## can replace the i-the population despite not completing one iteration\n            if fitnesses[0] &lt;= self.fitness[i]:\n                self.population[i] = trial\n                self.fitness[i] = fitnesses[0]\n            traj.extend(de_traj)\n            runtime.extend(de_runtime)\n            history.extend(de_history)\n\n    return traj, runtime, history\n</code></pre>"},{"location":"references/dehb/","title":"DEHB","text":""},{"location":"references/dehb/#dehb.optimizers.dehb.DEHBBase","title":"<code>DEHBBase(cs=None, f=None, dimensions=None, mutation_factor=None, crossover_prob=None, strategy=None, min_budget=None, max_budget=None, eta=None, min_clip=None, max_clip=None, boundary_fix_type='random', max_age=np.inf, **kwargs)</code>","text":"Source code in <code>src/dehb/optimizers/dehb.py</code> <pre><code>def __init__(self, cs=None, f=None, dimensions=None, mutation_factor=None,\n             crossover_prob=None, strategy=None, min_budget=None,\n             max_budget=None, eta=None, min_clip=None, max_clip=None,\n             boundary_fix_type='random', max_age=np.inf, **kwargs):\n    # Miscellaneous\n    self._setup_logger(kwargs)\n\n    # Benchmark related variables\n    self.cs = cs\n    self.configspace = True if isinstance(self.cs, ConfigSpace.ConfigurationSpace) else False\n    if self.configspace:\n        self.dimensions = len(self.cs.get_hyperparameters())\n    elif dimensions is None or not isinstance(dimensions, (int, np.integer)):\n        assert \"Need to specify `dimensions` as an int when `cs` is not available/specified!\"\n    else:\n        self.dimensions = dimensions\n    self.f = f\n\n    # DE related variables\n    self.mutation_factor = mutation_factor\n    self.crossover_prob = crossover_prob\n    self.strategy = strategy\n    self.fix_type = boundary_fix_type\n    self.max_age = max_age\n    self.de_params = {\n        \"mutation_factor\": self.mutation_factor,\n        \"crossover_prob\": self.crossover_prob,\n        \"strategy\": self.strategy,\n        \"configspace\": self.configspace,\n        \"boundary_fix_type\": self.fix_type,\n        \"max_age\": self.max_age,\n        \"cs\": self.cs,\n        \"dimensions\": self.dimensions,\n        \"f\": f\n    }\n\n    # Hyperband related variables\n    self.min_budget = min_budget\n    self.max_budget = max_budget\n    if self.max_budget &lt;= self.min_budget:\n        self.logger.error(\"Only (Max Budget &gt; Min Budget) is supported for DEHB.\")\n        if self.max_budget == self.min_budget:\n            self.logger.error(\n                \"If you have a fixed fidelity, \" \\\n                \"you can instead run DE. For more information checkout: \" \\\n                \"https://automl.github.io/DEHB/references/de\")\n        raise AssertionError()\n    self.eta = eta\n    self.min_clip = min_clip\n    self.max_clip = max_clip\n\n    # Precomputing budget spacing and number of configurations for HB iterations\n    self.max_SH_iter = None\n    self.budgets = None\n    if self.min_budget is not None and \\\n       self.max_budget is not None and \\\n       self.eta is not None:\n        self.max_SH_iter = -int(np.log(self.min_budget / self.max_budget) / np.log(self.eta)) + 1\n        self.budgets = self.max_budget * np.power(self.eta,\n                                                 -np.linspace(start=self.max_SH_iter - 1,\n                                                              stop=0, num=self.max_SH_iter))\n\n    # Updating DE parameter list\n    self.de_params.update({\"output_path\": self.output_path})\n\n    # Global trackers\n    self.population = None\n    self.fitness = None\n    self.inc_score = np.inf\n    self.inc_config = None\n    self.history = []\n</code></pre>"},{"location":"references/dehb/#dehb.optimizers.dehb.DEHBBase.get_next_iteration","title":"<code>get_next_iteration(iteration)</code>","text":"<p>Computes the Successive Halving spacing</p> <p>Given the iteration index, computes the budget spacing to be used and the number of configurations to be used for the SH iterations.</p>"},{"location":"references/dehb/#dehb.optimizers.dehb.DEHBBase.get_next_iteration--parameters","title":"Parameters","text":"<p>iteration : int     Iteration index clip : int, {1, 2, 3, ..., None}     If not None, clips the minimum number of configurations to 'clip'</p>"},{"location":"references/dehb/#dehb.optimizers.dehb.DEHBBase.get_next_iteration--returns","title":"Returns","text":"<p>ns : array budgets : array</p> Source code in <code>src/dehb/optimizers/dehb.py</code> <pre><code>def get_next_iteration(self, iteration):\n    '''Computes the Successive Halving spacing\n\n    Given the iteration index, computes the budget spacing to be used and\n    the number of configurations to be used for the SH iterations.\n\n    Parameters\n    ----------\n    iteration : int\n        Iteration index\n    clip : int, {1, 2, 3, ..., None}\n        If not None, clips the minimum number of configurations to 'clip'\n\n    Returns\n    -------\n    ns : array\n    budgets : array\n    '''\n    # number of 'SH runs'\n    s = self.max_SH_iter - 1 - (iteration % self.max_SH_iter)\n    # budget spacing for this iteration\n    budgets = self.budgets[(-s-1):]\n    # number of configurations in that bracket\n    n0 = int(np.floor((self.max_SH_iter)/(s+1)) * self.eta**s)\n    ns = [max(int(n0*(self.eta**(-i))), 1) for i in range(s+1)]\n    if self.min_clip is not None and self.max_clip is not None:\n        ns = np.clip(ns, a_min=self.min_clip, a_max=self.max_clip)\n    elif self.min_clip is not None:\n        ns = np.clip(ns, a_min=self.min_clip, a_max=np.max(ns))\n\n    return ns, budgets\n</code></pre>"},{"location":"references/dehb/#dehb.optimizers.dehb.DEHBBase.get_incumbents","title":"<code>get_incumbents()</code>","text":"<p>Returns a tuple of the (incumbent configuration, incumbent score/fitness).</p> Source code in <code>src/dehb/optimizers/dehb.py</code> <pre><code>def get_incumbents(self):\n    \"\"\" Returns a tuple of the (incumbent configuration, incumbent score/fitness). \"\"\"\n    if self.configspace:\n        return self.vector_to_configspace(self.inc_config), self.inc_score\n    return self.inc_config, self.inc_score\n</code></pre>"},{"location":"references/dehb/#dehb.optimizers.dehb.DEHB","title":"<code>DEHB(cs=None, f=None, dimensions=None, mutation_factor=0.5, crossover_prob=0.5, strategy='rand1_bin', min_budget=None, max_budget=None, eta=3, min_clip=None, max_clip=None, configspace=True, boundary_fix_type='random', max_age=np.inf, n_workers=None, client=None, async_strategy='immediate', **kwargs)</code>","text":"<p>             Bases: <code>DEHBBase</code></p> Source code in <code>src/dehb/optimizers/dehb.py</code> <pre><code>def __init__(self, cs=None, f=None, dimensions=None, mutation_factor=0.5,\n             crossover_prob=0.5, strategy='rand1_bin', min_budget=None,\n             max_budget=None, eta=3, min_clip=None, max_clip=None, configspace=True,\n             boundary_fix_type='random', max_age=np.inf, n_workers=None, client=None,\n             async_strategy=\"immediate\", **kwargs):\n    super().__init__(cs=cs, f=f, dimensions=dimensions, mutation_factor=mutation_factor,\n                     crossover_prob=crossover_prob, strategy=strategy, min_budget=min_budget,\n                     max_budget=max_budget, eta=eta, min_clip=min_clip, max_clip=max_clip,\n                     configspace=configspace, boundary_fix_type=boundary_fix_type,\n                     max_age=max_age, **kwargs)\n    self.de_params.update({\"async_strategy\": async_strategy})\n    self.iteration_counter = -1\n    self.de = {}\n    self._max_pop_size = None\n    self.active_brackets = []  # list of SHBracketManager objects\n    self.traj = []\n    self.runtime = []\n    self.history = []\n    self.start = None\n\n    # Dask variables\n    if n_workers is None and client is None:\n        raise ValueError(\"Need to specify either 'n_workers'(&gt;0) or 'client' (a Dask client)!\")\n    if client is not None and isinstance(client, Client):\n        self.client = client\n        self.n_workers = len(client.ncores())\n    else:\n        self.n_workers = n_workers\n        if self.n_workers &gt; 1:\n            self.client = Client(\n                n_workers=self.n_workers, processes=True, threads_per_worker=1, scheduler_port=0\n            )  # port 0 makes Dask select a random free port\n        else:\n            self.client = None\n    self.futures = []\n    self.shared_data = None\n\n    # Initializing DE subpopulations\n    self._get_pop_sizes()\n    self._init_subpop()\n\n    # Misc.\n    self.available_gpus = None\n    self.gpu_usage = None\n    self.single_node_with_gpus = None\n</code></pre>"},{"location":"references/dehb/#dehb.optimizers.dehb.DEHB.__getstate__","title":"<code>__getstate__()</code>","text":"<p>Allows the object to picklable while having Dask client as a class attribute.</p> Source code in <code>src/dehb/optimizers/dehb.py</code> <pre><code>def __getstate__(self):\n    \"\"\" Allows the object to picklable while having Dask client as a class attribute.\n    \"\"\"\n    d = dict(self.__dict__)\n    d[\"client\"] = None  # hack to allow Dask client to be a class attribute\n    d[\"logger\"] = None  # hack to allow logger object to be a class attribute\n    return d\n</code></pre>"},{"location":"references/dehb/#dehb.optimizers.dehb.DEHB.__del__","title":"<code>__del__()</code>","text":"<p>Ensures a clean kill of the Dask client and frees up a port.</p> Source code in <code>src/dehb/optimizers/dehb.py</code> <pre><code>def __del__(self):\n    \"\"\" Ensures a clean kill of the Dask client and frees up a port.\n    \"\"\"\n    if hasattr(self, \"client\") and isinstance(self, Client):\n        self.client.close()\n</code></pre>"},{"location":"references/dehb/#dehb.optimizers.dehb.DEHB.distribute_gpus","title":"<code>distribute_gpus()</code>","text":"<p>Function to create a GPU usage tracker dict.</p> <p>The idea is to extract the exact GPU device IDs available. During job submission, each submitted job is given a preference of a GPU device ID based on the GPU device with the least number of active running jobs. On retrieval of the result, this gpu usage dict is updated for the device ID that the finished job was mapped to.</p> Source code in <code>src/dehb/optimizers/dehb.py</code> <pre><code>def distribute_gpus(self):\n    \"\"\" Function to create a GPU usage tracker dict.\n\n    The idea is to extract the exact GPU device IDs available. During job submission, each\n    submitted job is given a preference of a GPU device ID based on the GPU device with the\n    least number of active running jobs. On retrieval of the result, this gpu usage dict is\n    updated for the device ID that the finished job was mapped to.\n    \"\"\"\n    try:\n        available_gpus = os.environ[\"CUDA_VISIBLE_DEVICES\"]\n        available_gpus = available_gpus.strip().split(\",\")\n        self.available_gpus = [int(_id) for _id in available_gpus]\n    except KeyError as e:\n        print(\"Unable to find valid GPU devices. \"\n              \"Environment variable {} not visible!\".format(str(e)))\n        self.available_gpus = []\n    self.gpu_usage = dict()\n    for _id in self.available_gpus:\n        self.gpu_usage[_id] = 0\n</code></pre>"},{"location":"references/dehb/#dehb.optimizers.dehb.DEHB.clean_inactive_brackets","title":"<code>clean_inactive_brackets()</code>","text":"<p>Removes brackets from the active list if it is done as communicated by Bracket Manager</p> Source code in <code>src/dehb/optimizers/dehb.py</code> <pre><code>def clean_inactive_brackets(self):\n    \"\"\" Removes brackets from the active list if it is done as communicated by Bracket Manager\n    \"\"\"\n    if len(self.active_brackets) == 0:\n        return\n    self.active_brackets = [\n        bracket for bracket in self.active_brackets if ~bracket.is_bracket_done()\n    ]\n    return\n</code></pre>"},{"location":"references/dehb/#dehb.optimizers.dehb.DEHB.is_worker_available","title":"<code>is_worker_available(verbose=False)</code>","text":"<p>Checks if at least one worker is available to run a job</p> Source code in <code>src/dehb/optimizers/dehb.py</code> <pre><code>def is_worker_available(self, verbose=False):\n    \"\"\" Checks if at least one worker is available to run a job\n    \"\"\"\n    if self.n_workers == 1 or self.client is None or not isinstance(self.client, Client):\n        # in the synchronous case, one worker is always available\n        return True\n    # checks the absolute number of workers mapped to the client scheduler\n    # client.ncores() should return a dict with the keys as unique addresses to these workers\n    # treating the number of available workers in this manner\n    workers = self._get_worker_count()  # len(self.client.ncores())\n    if len(self.futures) &gt;= workers:\n        # pause/wait if active worker count greater allocated workers\n        return False\n    return True\n</code></pre>"},{"location":"references/dehb/#dehb.optimizers.dehb.DEHB.submit_job","title":"<code>submit_job(job_info, **kwargs)</code>","text":"<p>Asks a free worker to run the objective function on config and budget</p> Source code in <code>src/dehb/optimizers/dehb.py</code> <pre><code>def submit_job(self, job_info, **kwargs):\n    \"\"\" Asks a free worker to run the objective function on config and budget\n    \"\"\"\n    job_info[\"kwargs\"] = self.shared_data if self.shared_data is not None else kwargs\n    # submit to to Dask client\n    if self.n_workers &gt; 1 or isinstance(self.client, Client):\n        if self.single_node_with_gpus:\n            # managing GPU allocation for the job to be submitted\n            job_info.update({\"gpu_devices\": self._get_gpu_id_with_low_load()})\n        self.futures.append(\n            self.client.submit(self._f_objective, job_info)\n        )\n    else:\n        # skipping scheduling to Dask worker to avoid added overheads in the synchronous case\n        self.futures.append(self._f_objective(job_info))\n\n    # pass information of job submission to Bracket Manager\n    for bracket in self.active_brackets:\n        if bracket.bracket_id == job_info['bracket_id']:\n            # registering is IMPORTANT for Bracket Manager to perform SH\n            bracket.register_job(job_info['budget'])\n            break\n</code></pre>"},{"location":"references/dehb/#dehb.optimizers.dehb.DEHB.run","title":"<code>run(fevals=None, brackets=None, total_cost=None, single_node_with_gpus=False, verbose=False, debug=False, save_intermediate=True, save_history=True, name=None, **kwargs)</code>","text":"<p>Main interface to run optimization by DEHB</p> <p>This function waits on workers and if a worker is free, asks for a configuration and a budget to evaluate on and submits it to the worker. In each loop, it checks if a job is complete, fetches the results, carries the necessary processing of it asynchronously to the worker computations.</p> <p>The duration of the DEHB run can be controlled by specifying one of 3 parameters. If more than one are specified, DEHB selects only one in the priority order (high to low): 1) Number of function evaluations (fevals) 2) Number of Successive Halving brackets run under Hyperband (brackets) 3) Total computational cost (in seconds) aggregated by all function evaluations (total_cost)</p> Source code in <code>src/dehb/optimizers/dehb.py</code> <pre><code>@logger.catch\ndef run(self, fevals=None, brackets=None, total_cost=None, single_node_with_gpus=False,\n        verbose=False, debug=False, save_intermediate=True, save_history=True, name=None, **kwargs):\n    \"\"\" Main interface to run optimization by DEHB\n\n    This function waits on workers and if a worker is free, asks for a configuration and a\n    budget to evaluate on and submits it to the worker. In each loop, it checks if a job\n    is complete, fetches the results, carries the necessary processing of it asynchronously\n    to the worker computations.\n\n    The duration of the DEHB run can be controlled by specifying one of 3 parameters. If more\n    than one are specified, DEHB selects only one in the priority order (high to low):\n    1) Number of function evaluations (fevals)\n    2) Number of Successive Halving brackets run under Hyperband (brackets)\n    3) Total computational cost (in seconds) aggregated by all function evaluations (total_cost)\n    \"\"\"\n    # checks if a Dask client exists\n    if len(kwargs) &gt; 0 and self.n_workers &gt; 1 and isinstance(self.client, Client):\n        # broadcasts all additional data passed as **kwargs to all client workers\n        # this reduces overload in the client-worker communication by not having to\n        # serialize the redundant data used by all workers for every job\n        self.shared_data = self.client.scatter(kwargs, broadcast=True)\n\n    # allows each worker to be mapped to a different GPU when running on a single node\n    # where all available GPUs are accessible\n    self.single_node_with_gpus = single_node_with_gpus\n    if self.single_node_with_gpus:\n        self.distribute_gpus()\n\n    self.start = time.time()\n    if verbose:\n        print(\"\\nLogging at {} for optimization starting at {}\\n\".format(\n            os.path.join(os.getcwd(), self.log_filename),\n            time.strftime(\"%x %X %Z\", time.localtime(self.start))\n        ))\n    if debug:\n        logger.configure(handlers=[{\"sink\": sys.stdout}])\n    while True:\n        if self._is_run_budget_exhausted(fevals, brackets, total_cost):\n            break\n        if self.is_worker_available():\n            job_info = self._get_next_job()\n            if brackets is not None and job_info['bracket_id'] &gt;= brackets:\n                # ignore submission and only collect results\n                # when brackets are chosen as run budget, an extra bracket is created\n                # since iteration_counter is incremented in _get_next_job() and then checked\n                # in _is_run_budget_exhausted(), therefore, need to skip suggestions\n                # coming from the extra allocated bracket\n                # _is_run_budget_exhausted() will not return True until all the lower brackets\n                # have finished computation and returned its results\n                pass\n            else:\n                if self.n_workers &gt; 1 or isinstance(self.client, Client):\n                    self.logger.debug(\"{}/{} worker(s) available.\".format(\n                        self._get_worker_count() - len(self.futures), self._get_worker_count()\n                    ))\n                # submits job_info to a worker for execution\n                self.submit_job(job_info, **kwargs)\n                if verbose:\n                    budget = job_info['budget']\n                    self._verbosity_runtime(fevals, brackets, total_cost)\n                    self.logger.info(\n                        \"Evaluating a configuration with budget {} under \"\n                        \"bracket ID {}\".format(budget, job_info['bracket_id'])\n                    )\n                    self.logger.info(\n                        \"Best score seen/Incumbent score: {}\".format(self.inc_score)\n                    )\n                self._verbosity_debug()\n        self._fetch_results_from_workers()\n        if save_intermediate and self.inc_config is not None:\n            self._save_incumbent(name)\n        if save_history and self.history is not None:\n            self._save_history(name)\n        self.clean_inactive_brackets()\n    # end of while\n\n    if verbose and len(self.futures) &gt; 0:\n        self.logger.info(\n            \"DEHB optimisation over! Waiting to collect results from workers running...\"\n        )\n    while len(self.futures) &gt; 0:\n        self._fetch_results_from_workers()\n        if save_intermediate and self.inc_config is not None:\n            self._save_incumbent(name)\n        if save_history and self.history is not None:\n            self._save_history(name)\n        time.sleep(0.05)  # waiting 50ms\n\n    if verbose:\n        time_taken = time.time() - self.start\n        self.logger.info(\"End of optimisation! Total duration: {}; Total fevals: {}\\n\".format(\n            time_taken, len(self.traj)\n        ))\n        self.logger.info(\"Incumbent score: {}\".format(self.inc_score))\n        self.logger.info(\"Incumbent config: \")\n        if self.configspace:\n            config = self.vector_to_configspace(self.inc_config)\n            for k, v in config.get_dictionary().items():\n                self.logger.info(\"{}: {}\".format(k, v))\n        else:\n            self.logger.info(\"{}\".format(self.inc_config))\n    self._save_incumbent(name)\n    self._save_history(name)\n    return np.array(self.traj), np.array(self.runtime), np.array(self.history, dtype=object)\n</code></pre>"}]}